{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, ensure_tuple\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.label_type = label_type\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_\"+param.label_type+\"_label.nii.gz\")))\n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dictionary\n",
      "Reading labeled images from: /Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook\n",
      "Use magnitude/phase images\n",
      "/Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz\n",
      "/Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()\n",
    "pixel_dim = (3.6, 1.171875, 1.171875)\n",
    "window_size = (3, 48, 48)\n",
    "orientation = 'PIL'\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "input_type = 'MP'\n",
    "label_type = 'multi'\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sikt ORIGINAL\n",
      "(1.171875, 1.171875, 3.6000001430511475)\n",
      "(-112.5, 18.399999618530273, 112.5)\n",
      "(1.0, 0.0, 0.0, 0.0, -0.0, 1.0, 0.0, -1.0, 0.0)\n",
      "CHECK ITK from META\n",
      "itkMatrixD33 ([[1.0, 0.0, 0.0], [0.0, -0.0, 1.0], [0.0, -1.0, 0.0]])\n",
      "CHECK Sitk from META\n",
      "(1.171875, 1.171875, 3.6000001430511475)\n",
      "(-112.5, 18.399999618530273, 112.5)\n",
      "(1.0, 0.0, 0.0, 0.0, -0.0, 1.0, 0.0, -1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# TEST METADATA Converstion\n",
    "import itk\n",
    "sitk_image_1 = sitk.ReadImage(train_files[0]['image_1'], sitk.sitkFloat32)\n",
    "itk_image_1 = itk.imread(train_files[0]['image_1']).astype(itk.F)\n",
    "\n",
    "# Original\n",
    "# spacing = itk_image_1.GetSpacing()\n",
    "# origin = itk_image_1.GetOrigin()\n",
    "# direction = itk_image_1.GetDirection()\n",
    "# print('ITK ORIGINAL')\n",
    "# print(direction)\n",
    "# print(origin)\n",
    "# print(direction)\n",
    "\n",
    "spacing = sitk_image_1.GetSpacing()\n",
    "origin = sitk_image_1.GetOrigin()\n",
    "direction = sitk_image_1.GetDirection()\n",
    "print('Sikt ORIGINAL')\n",
    "print(spacing)\n",
    "print(origin)\n",
    "print(direction)\n",
    "\n",
    "# Get from ITK to META\n",
    "spacing = np.asarray(itk_image_1.GetSpacing())\n",
    "origin = np.asarray(itk_image_1.GetOrigin())\n",
    "direction = itk.array_from_matrix(itk_image_1.GetDirection())\n",
    "\n",
    "direction = np.asarray(direction)\n",
    "sr = min(max(direction.shape[0], 1), 3)\n",
    "affine: np.ndarray = np.eye(sr + 1)\n",
    "affine[:sr, :sr] = direction[:sr, :sr] @ np.diag(spacing[:sr])\n",
    "affine[:sr, -1] = origin[:sr]\n",
    "# print('META')\n",
    "# print(spacing)\n",
    "# print(origin)\n",
    "# print(direction)\n",
    "# print(affine)\n",
    "\n",
    "# From META to itk\n",
    "from monai.utils import get_equivalent_dtype, convert_data_type\n",
    "from monai.data.utils import to_affine_nd, affine_to_spacing, orientation_ras_lps\n",
    "\n",
    "print('CHECK ITK from META')\n",
    "d = len(itk.size(itk_image_1))\n",
    "if affine is None:\n",
    "    affine = np.eye(d + 1, dtype=np.float64)\n",
    "_affine = convert_data_type(affine, np.ndarray)[0]\n",
    "spacing = affine_to_spacing(_affine, r=d)\n",
    "_direction: np.ndarray = np.diag(1 / spacing)\n",
    "_direction = _affine[:d, :d] @ _direction\n",
    "itk_image_1.SetSpacing(spacing.tolist())\n",
    "itk_image_1.SetOrigin(_affine[:d, -1].tolist())\n",
    "itk_image_1.SetDirection(itk.GetMatrixFromArray(_direction))\n",
    "print(itk_image_1.GetDirection())\n",
    "\n",
    "# Make same for sitk\n",
    "print('CHECK Sitk from META')\n",
    "d = len(sitk_image_1.GetSize())\n",
    "if affine is None:\n",
    "    affine = np.eye(d + 1, dtype=np.float64)\n",
    "_affine = convert_data_type(affine, np.ndarray)[0]\n",
    "spacing = affine_to_spacing(_affine, r=d)\n",
    "_direction: np.ndarray = np.diag(1 / spacing)\n",
    "_direction = _affine[:d, :d] @ _direction\n",
    "sitk_image_1.SetSpacing(spacing.tolist())\n",
    "sitk_image_1.SetOrigin(_affine[:d, -1].tolist())\n",
    "sitk_image_1.SetDirection(_direction.ravel().tolist())\n",
    "print(sitk_image_1.GetSpacing())\n",
    "print(sitk_image_1.GetOrigin())\n",
    "print(sitk_image_1.GetDirection())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW CUSTOM IMAGE LOADERS\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data._utils.collate import np_str_obj_array_pattern\n",
    "from monai.data import MetaTensor, ImageReader, ITKReader\n",
    "from monai.data.utils import orientation_ras_lps, is_no_channel\n",
    "from monai.config import DtypeLike, KeysCollection, NdarrayOrTensor\n",
    "from monai.utils import convert_to_dst_type, ensure_tuple, ensure_tuple_rep, get_equivalent_dtype, MetaKeys, SpaceKeys, TraceKeys\n",
    "from monai.transforms import Transform, MapTransform\n",
    "from monai.utils.enums import PostFix\n",
    "DEFAULT_POST_FIX = PostFix.meta()\n",
    "\n",
    "class sitkReader(ImageReader):\n",
    "    def __init__(\n",
    "            self,\n",
    "            series_name: str = \"\",\n",
    "            reverse_indexing: bool = False,\n",
    "            series_meta: bool = False,\n",
    "            affine_lps_to_ras: bool = True,\n",
    "            **kwargs,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.series_name = series_name\n",
    "        self.reverse_indexing = reverse_indexing\n",
    "        self.series_meta = series_meta\n",
    "        self.affine_lps_to_ras = affine_lps_to_ras\n",
    "    \n",
    "    def read(self, img):\n",
    "        return img\n",
    "    \n",
    "    def verify_suffix(self, img) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def get_data(self, img) -> tuple[np.ndarray, dict]:\n",
    "        img_array: list[np.ndarray] = []\n",
    "        compatible_meta: dict = {}\n",
    "        data = self._get_array_data(img)\n",
    "        img_array.append(data)\n",
    "        header = self._get_meta_dict(img)\n",
    "        header[MetaKeys.ORIGINAL_AFFINE] = self._get_affine(img, self.affine_lps_to_ras)\n",
    "        header[MetaKeys.SPACE] = SpaceKeys.RAS if self.affine_lps_to_ras else SpaceKeys.LPS\n",
    "        header[MetaKeys.AFFINE] = header[MetaKeys.ORIGINAL_AFFINE].copy()\n",
    "        header[MetaKeys.SPATIAL_SHAPE] = self._get_spatial_shape(img)\n",
    "        # default to \"no_channel\" or -1\n",
    "        header[MetaKeys.ORIGINAL_CHANNEL_DIM] = (float(\"nan\") if len(data.shape) == len(header[MetaKeys.SPATIAL_SHAPE]) else -1)\n",
    "        self._copy_compatible_dict(header, compatible_meta)\n",
    "        return self._stack_images(img_array, compatible_meta), compatible_meta\n",
    "        \n",
    "    def _get_meta_dict(self, img) -> dict:\n",
    "        img_meta_dict = img.GetMetaDataKeys()\n",
    "        meta_dict: dict = {}\n",
    "        for key in img_meta_dict:\n",
    "            if key.startswith(\"ITK_\"):\n",
    "                continue\n",
    "            val = img.GetMetaData(key)\n",
    "            meta_dict[key] = np.asarray(val) if type(val).__name__.startswith(\"itk\") else val\n",
    "        meta_dict[\"spacing\"] = np.asarray(img.GetSpacing())\n",
    "        return dict(meta_dict)\n",
    "\n",
    "    def _get_affine(self, img, lps_to_ras: bool = True):\n",
    "        dir_array = img.GetDirection()\n",
    "        direction = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]])\n",
    "        spacing = np.asarray(img.GetSpacing())\n",
    "        origin = np.asarray(img.GetOrigin())\n",
    "        sr = min(max(direction.shape[0], 1), 3)\n",
    "        affine: np.ndarray = np.eye(sr + 1)\n",
    "        affine[:sr, :sr] = direction[:sr, :sr] @ np.diag(spacing[:sr])\n",
    "        affine[:sr, -1] = origin[:sr]\n",
    "        if lps_to_ras:\n",
    "            affine = orientation_ras_lps(affine)\n",
    "        return affine\n",
    "\n",
    "    def _get_spatial_shape(self, img):\n",
    "        ## Not handling multichannel images with SimpleITK\n",
    "        dir_array = img.GetDirection()\n",
    "        sr = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]]).shape[0]\n",
    "        sr = max(min(sr, 3), 1)\n",
    "        _size = list(img.GetSize())\n",
    "        return np.asarray(_size[:sr])\n",
    "\n",
    "    def _get_array_data(self, img):\n",
    "        ## Not handling multichannel images with SimpleITK\n",
    "        np_img = sitk.GetArrayFromImage(img)\n",
    "        return np_img if self.reverse_indexing else np_img.T\n",
    "    \n",
    "    def _stack_images(self, image_list: list, meta_dict: dict):\n",
    "        if len(image_list) <= 1:\n",
    "            return image_list[0]\n",
    "        if not is_no_channel(meta_dict.get(MetaKeys.ORIGINAL_CHANNEL_DIM, None)):\n",
    "            channel_dim = int(meta_dict[MetaKeys.ORIGINAL_CHANNEL_DIM])\n",
    "            return np.concatenate(image_list, axis=channel_dim)\n",
    "        # stack at a new first dim as the channel dim, if `'original_channel_dim'` is unspecified\n",
    "        meta_dict[MetaKeys.ORIGINAL_CHANNEL_DIM] = 0\n",
    "        return np.stack(image_list, axis=0)\n",
    "\n",
    "    def _copy_compatible_dict(self, from_dict: dict, to_dict: dict):\n",
    "        if not isinstance(to_dict, dict):\n",
    "            raise ValueError(f\"to_dict must be a Dict, got {type(to_dict)}.\")\n",
    "        if not to_dict:\n",
    "            for key in from_dict:\n",
    "                datum = from_dict[key]\n",
    "                if isinstance(datum, np.ndarray) and np_str_obj_array_pattern.search(datum.dtype.str) is not None:\n",
    "                    continue\n",
    "                to_dict[key] = str(TraceKeys.NONE) if datum is None else datum  # NoneType to string for default_collate\n",
    "        else:\n",
    "            affine_key, shape_key = MetaKeys.AFFINE, MetaKeys.SPATIAL_SHAPE\n",
    "            if affine_key in from_dict and not np.allclose(from_dict[affine_key], to_dict[affine_key]):\n",
    "                raise RuntimeError(\n",
    "                    \"affine matrix of all images should be the same for channel-wise concatenation. \"\n",
    "                    f\"Got {from_dict[affine_key]} and {to_dict[affine_key]}.\"\n",
    "                )\n",
    "            if shape_key in from_dict and not np.allclose(from_dict[shape_key], to_dict[shape_key]):\n",
    "                raise RuntimeError(\n",
    "                    \"spatial_shape of all images should be the same for channel-wise concatenation. \"\n",
    "                    f\"Got {from_dict[shape_key]} and {to_dict[shape_key]}.\"\n",
    "            )\n",
    "                \n",
    "class LoadSitkImage(Transform):\n",
    "    def __init__(self,\n",
    "            image_only: bool = False,\n",
    "            dtype: DtypeLike or None = np.float32,\n",
    "            ensure_channel_first: bool = False,\n",
    "            simple_keys: bool = False,\n",
    "            prune_meta_pattern: str or None = None,\n",
    "            prune_meta_sep: str = \".\",   \n",
    "        ) -> None:\n",
    "        self.reader = sitkReader()\n",
    "        self.image_only = image_only\n",
    "        self.ensure_channel_first = ensure_channel_first\n",
    "        self.dtype = dtype\n",
    "        self.simple_keys = simple_keys\n",
    "        self.pattern = prune_meta_pattern\n",
    "        self.sep = prune_meta_sep\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, sitk.SimpleITK.Image):\n",
    "            raise RuntimeError(f\"{self.__class__.__name__} The input image is not an ITK object.\\n\")    \n",
    "        img_array, meta_data = self.reader.get_data(img)\n",
    "        img_array = convert_to_dst_type(img_array, dst=img_array, dtype=self.dtype)[0]\n",
    "        if not isinstance(meta_data, dict):\n",
    "            raise ValueError(f\"`meta_data` must be a dict, got type {type(meta_data)}.\")\n",
    "        # Here I changed from original LoadImage to use tensor instead of numpy array (img_array) \n",
    "        # so the result is similar to loading the nifti file with LoadImage\n",
    "        img = MetaTensor.ensure_torch_and_prune_meta(\n",
    "            torch.from_numpy(img_array), meta_data, self.simple_keys, pattern=self.pattern, sep=self.sep\n",
    "        )\n",
    "        if self.ensure_channel_first:\n",
    "            img = EnsureChannelFirst()(img)\n",
    "        if self.image_only:\n",
    "            return img\n",
    "        return img, img.meta if isinstance(img, MetaTensor) else meta_data\n",
    "\n",
    "\n",
    "import itk \n",
    "class LoadITKImage(Transform):\n",
    "    def __init__(self,\n",
    "            image_only: bool = False,\n",
    "            dtype: DtypeLike or None = np.float32,\n",
    "            ensure_channel_first: bool = False,\n",
    "            simple_keys: bool = False,\n",
    "            prune_meta_pattern: str or None = None,\n",
    "            prune_meta_sep: str = \".\",   \n",
    "        ) -> None:\n",
    "        self.reader = ITKReader()\n",
    "        self.image_only = image_only\n",
    "        self.ensure_channel_first = ensure_channel_first\n",
    "        self.dtype = dtype\n",
    "        self.simple_keys = simple_keys\n",
    "        self.pattern = prune_meta_pattern\n",
    "        self.sep = prune_meta_sep\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, itk.itkImagePython.itkImageF3):\n",
    "            raise RuntimeError(f\"{self.__class__.__name__} The input image is not an ITK object.\\n\")\n",
    "        img_array, meta_data = self.reader.get_data(img)\n",
    "        img_array = convert_to_dst_type(img_array, dst=img_array, dtype=self.dtype)[0]\n",
    "        if not isinstance(meta_data, dict):\n",
    "            raise ValueError(f\"`meta_data` must be a dict, got type {type(meta_data)}.\")\n",
    "        # Here I changed from original LoadImage to use tensor instead of numpy array (img_array) \n",
    "        # so the result is similar to loading the nifti file with LoadImage\n",
    "        img = MetaTensor.ensure_torch_and_prune_meta(\n",
    "            torch.from_numpy(img_array), meta_data, self.simple_keys, pattern=self.pattern, sep=self.sep\n",
    "        )\n",
    "        if self.ensure_channel_first:\n",
    "            img = EnsureChannelFirst()(img)\n",
    "        if self.image_only:\n",
    "            return img\n",
    "        return img, img.meta if isinstance(img, MetaTensor) else meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadSitkImaged(MapTransform):\n",
    "    def __init__(self,\n",
    "            keys: KeysCollection,\n",
    "            dtype: DtypeLike = np.float32,\n",
    "            meta_keys: KeysCollection or None=None,\n",
    "            meta_key_postfix: str=DEFAULT_POST_FIX,\n",
    "            overwriting: bool=False,\n",
    "            image_only: bool=False,\n",
    "            ensure_channel_first: bool=False,\n",
    "            simple_keys: bool=False,\n",
    "            prune_meta_pattern: str or None=None,\n",
    "            prune_meta_sep: str=\".\",\n",
    "            allow_missing_keys: bool=False,\n",
    "        ):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self._loader = LoadSitkImage(\n",
    "            image_only,\n",
    "            dtype,\n",
    "            ensure_channel_first,\n",
    "            simple_keys,\n",
    "            prune_meta_pattern,\n",
    "            prune_meta_sep\n",
    "        ) \n",
    "        if not isinstance(meta_key_postfix, str):\n",
    "            raise TypeError(f\"meta_key_postfix must be a str but is {type(meta_key_postfix).__name__}.\")\n",
    "        self.meta_keys = ensure_tuple_rep(None, len(self.keys)) if meta_keys is None else ensure_tuple(meta_keys)\n",
    "        if len(self.keys) != len(self.meta_keys):\n",
    "            raise ValueError(\n",
    "                f\"meta_keys should have the same length as keys, got {len(self.keys)} and {len(self.meta_keys)}.\"\n",
    "            )\n",
    "        self.meta_key_postfix = ensure_tuple_rep(meta_key_postfix, len(self.keys))\n",
    "        self.overwriting = overwriting\n",
    "        \n",
    "        \n",
    "    def __call__(self, img):\n",
    "        d = dict(img)\n",
    "        for key, meta_key, meta_key_postfix in self.key_iterator(d, self.meta_keys, self.meta_key_postfix):\n",
    "            img = self._loader(d[key])\n",
    "            if self._loader.image_only:\n",
    "                d[key] = img\n",
    "            else:\n",
    "                if not isinstance(img, (tuple, list)):\n",
    "                    raise ValueError(\n",
    "                        f\"loader must return a tuple or list (because image_only=False was used), got {type(data)}.\"\n",
    "                    )\n",
    "                d[key] = img[0]\n",
    "                if not isinstance(img[1], dict):\n",
    "                    raise ValueError(f\"metadata must be a dict, got {type(img[1])}.\")\n",
    "                meta_key = meta_key or f\"{key}_{meta_key_postfix}\"\n",
    "                if meta_key in d and not self.overwriting:\n",
    "                    raise KeyError(f\"Metadata with key {meta_key} already exists and overwriting=False.\")\n",
    "                d[meta_key] = img[1]\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on SaveImage transform and ITKWriter set_data_array and set_metadata functions\n",
    "import warnings\n",
    "from monai.utils import get_equivalent_dtype, convert_data_type, GridSampleMode, GridSamplePadMode\n",
    "from monai.data.utils import to_affine_nd, affine_to_spacing\n",
    "from monai.data.image_writer import ImageWriter\n",
    "from typing import TYPE_CHECKING, Any, cast\n",
    "\n",
    "# Basically a copy from ITKWriter. Only differences are in create_backend_obj function and the lack or write function\n",
    "class sitkWriter(ImageWriter):\n",
    "    def __init__(self,\n",
    "            output_dtype: DtypeLike or None=np.float32, \n",
    "            affine_lps_to_ras: bool or None=True,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(output_dtype=output_dtype, affine_lps_to_ras=affine_lps_to_ras, affine=None, channel_dim=0, **kwargs)\n",
    "        \n",
    "    def set_data_array(self, data_array: NdarrayOrTensor, channel_dim: int or None=0, squeeze_end_dims: bool=True, **kwargs):\n",
    "        n_chns = data_array.shape[channel_dim] if channel_dim is not None else 0\n",
    "        self.data_obj = self.convert_to_channel_last(\n",
    "            data=data_array,\n",
    "            channel_dim=channel_dim,\n",
    "            squeeze_end_dims=squeeze_end_dims,\n",
    "            spatial_ndim=kwargs.pop(\"spatial_ndim\", 3),\n",
    "            contiguous=kwargs.pop(\"contiguous\", True),\n",
    "        )\n",
    "        self.channel_dim = -1  # in most cases, the data is set to channel last\n",
    "        if squeeze_end_dims and n_chns <= 1:  # num_channel==1 squeezed\n",
    "            self.channel_dim = None\n",
    "        if not squeeze_end_dims and n_chns < 1:  # originally no channel and convert_to_channel_last added a channel\n",
    "            self.channel_dim = None\n",
    "            self.data_obj = self.data_obj[..., 0]\n",
    "    \n",
    "    def set_metadata(self, meta_dict: Mapping or None = None, resample: bool = True, **options):\n",
    "        original_affine, affine, spatial_shape = self.get_meta_info(meta_dict)\n",
    "        if self.output_dtype is None and hasattr(self.data_obj, \"dtype\"):  # pylint: disable=E0203\n",
    "            self.output_dtype = self.data_obj.dtype  # type: ignore\n",
    "        self.data_obj, self.affine = self.resample_if_needed(\n",
    "            data_array=cast(NdarrayOrTensor, self.data_obj),\n",
    "            affine=affine,\n",
    "            target_affine=original_affine if resample else None,\n",
    "            output_spatial_shape=spatial_shape if resample else None,\n",
    "            mode=options.pop(\"mode\", GridSampleMode.BILINEAR),\n",
    "            padding_mode=options.pop(\"padding_mode\", GridSamplePadMode.BORDER),\n",
    "            align_corners=options.pop(\"align_corners\", False),\n",
    "            dtype=options.pop(\"dtype\", np.float64),\n",
    "        )\n",
    "    \n",
    "    def create_backend_obj(\n",
    "            self, # Not sure if needed\n",
    "            data_array: NdarrayOrTensor,\n",
    "            channel_dim: int or None=0,\n",
    "            affine: NdarrayOrTensor or None=None,\n",
    "            dtype: DtypeLike = np.float32,\n",
    "            affine_lps_to_ras: bool or None=True,\n",
    "            **kwargs,\n",
    "        )-> sitk.SimpleITK.Image:\n",
    "        if isinstance(data_array, MetaTensor) and affine_lps_to_ras is None:\n",
    "            # do the converting from LPS to RAS only if the space type is currently LPS.\n",
    "            affine_lps_to_ras = (data_array.meta.get(MetaKeys.SPACE, SpaceKeys.LPS) != SpaceKeys.LPS)  \n",
    "        data_array = convert_data_type(data_array, np.ndarray)[0]\n",
    "        _is_vec = channel_dim is not None\n",
    "        if _is_vec:\n",
    "            data_array = np.moveaxis(data_array, -1, 0)  # from channel last to channel first\n",
    "        data_array = data_array.T.astype(get_equivalent_dtype(dtype, np.ndarray), copy=True, order=\"C\")\n",
    "        sitk_image = sitk.GetImageFromArray(data_array, isVector=_is_vec)\n",
    "        d = len(sitk_image.GetSize())\n",
    "        if affine is None:\n",
    "            affine = np.eye(d + 1, dtype=np.float64)\n",
    "        _affine = convert_data_type(affine, np.ndarray)[0]\n",
    "        if affine_lps_to_ras:\n",
    "            _affine = orientation_ras_lps(to_affine_nd(d, _affine))\n",
    "        spacing = affine_to_spacing(_affine, r=d)\n",
    "        _direction: np.ndarray = np.diag(1 / spacing)\n",
    "        _direction = _affine[:d, :d] @ _direction\n",
    "        sitk_image.SetSpacing(spacing.tolist())\n",
    "        sitk_image.SetOrigin(_affine[:d, -1].tolist())\n",
    "        sitk_image.SetDirection(_direction.ravel().tolist())\n",
    "        return sitk_image\n",
    "    \n",
    "    # Maybe not necessary\n",
    "    def write(self, verbose: bool = False, **kwargs):\n",
    "        super().write('sitkImage', verbose=verbose)\n",
    "        self.data_obj = self.create_backend_obj(\n",
    "            cast(NdarrayOrTensor, self.data_obj),\n",
    "            channel_dim=self.channel_dim,\n",
    "            affine=self.affine,\n",
    "            dtype=self.output_dtype,\n",
    "            affine_lps_to_ras=self.affine_lps_to_ras,  # type: ignore\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self.data_obj    \n",
    "        \n",
    "class PushSitkImage(Transform):\n",
    "    def __init__(self,\n",
    "            output_dtype: DtypeLike or None = np.float32,\n",
    "            dtype: DtypeLike or None=np.float32, \n",
    "            resample: bool = True,\n",
    "            mode: str = \"nearest\",\n",
    "            padding_mode: str = GridSamplePadMode.BORDER,\n",
    "            scale: int or None = None,\n",
    "            squeeze_end_dims: bool = True,\n",
    "            print_log: bool = True,\n",
    "            channel_dim: int or None = 0,\n",
    "        ) -> sitk.SimpleITK.Image:\n",
    "        self.init_kwargs = {\"output_dtype\": output_dtype,\"scale\": scale}\n",
    "        self.data_kwargs = {\"squeeze_end_dims\": squeeze_end_dims, \"channel_dim\": channel_dim}\n",
    "        self.meta_kwargs = {\"resample\": resample, \"mode\": mode, \"padding_mode\": padding_mode, \"dtype\": dtype}\n",
    "        self.write_kwargs = {\"verbose\": print_log}\n",
    "        self.writer = sitkWriter(**self.init_kwargs)\n",
    "        \n",
    "    # Not sure this is needed\n",
    "    # def set_options(self, init_kwargs=None, data_kwargs=None, meta_kwargs=None, write_kwargs=None):\n",
    "    #     if init_kwargs is not None:\n",
    "    #         self.init_kwargs.update(init_kwargs)\n",
    "    #     if data_kwargs is not None:\n",
    "    #         self.data_kwargs.update(data_kwargs)\n",
    "    #     if meta_kwargs is not None:\n",
    "    #         self.meta_kwargs.update(meta_kwargs)\n",
    "    #     if write_kwargs is not None:\n",
    "    #         self.write_kwargs.update(write_kwargs)\n",
    "    #     return self\n",
    "        \n",
    "    def __call__(self, img: torch.Tensor or np.ndarray, meta_data: dict or None = None):\n",
    "        meta_data = img.meta if isinstance(img, MetaTensor) else meta_data\n",
    "        if meta_data:\n",
    "            meta_spatial_shape = ensure_tuple(meta_data.get(\"spatial_shape\", ()))\n",
    "            if len(meta_spatial_shape) >= len(img.shape):\n",
    "                self.data_kwargs[\"channel_dim\"] = None\n",
    "            elif is_no_channel(self.data_kwargs.get(\"channel_dim\")):\n",
    "                warnings.warn(\n",
    "                    f\"data shape {img.shape} (with spatial shape {meta_spatial_shape}) \"\n",
    "                    f\"but SaveImage `channel_dim` is set to {self.data_kwargs.get('channel_dim')} no channel.\"\n",
    "                )\n",
    "        self.writer.set_data_array(data_array=img, **self.data_kwargs)\n",
    "        self.writer.set_metadata(meta_dict=meta_data, **self.meta_kwargs)\n",
    "        return self.writer.write(**self.write_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192 192   3]\n",
      "[192 192   3]\n",
      "[192 192   3]\n"
     ]
    }
   ],
   "source": [
    "import itk\n",
    "\n",
    "itk_img = itk.imread(train_files[0]['image_1']).astype(itk.F)\n",
    "sitk_img = sitk.ReadImage(train_files[0]['image_1'], sitk.sitkFloat32)\n",
    "\n",
    "# print(sitk_img.GetSpacing())\n",
    "# print(itk.affine_lps_to_ras(itk_img))\n",
    "\n",
    "itk_img.GetNumberOfComponentsPerPixel\n",
    "\n",
    "\n",
    "dir_array = sitk_img.GetDirection()\n",
    "sr = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]]).shape[0]\n",
    "sr = max(min(sr, 3), 1)\n",
    "_size = list(sitk_img.GetSize())\n",
    "print(np.asarray(_size[:sr]))\n",
    "\n",
    "\n",
    "\n",
    "sr = itk.array_from_matrix(itk_img.GetDirection()).shape[0]\n",
    "sr = max(min(sr, 3), 1)\n",
    "_size = list(itk.size(itk_img))\n",
    "print(np.asarray(_size[:sr]))\n",
    "    \n",
    "    \n",
    "# print(itk.array_from_matrix(itk_img.GetDirection()))\n",
    "# itk.array_from_matrix(img.GetDirection()).shape[0]\n",
    "\n",
    "print(np.asarray(sitk_img.GetSize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz\n",
      "/Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz\n",
      "2023-09-28 16:27:14,455 INFO image_writer.py:197 - writing: sitkImage\n",
      "2023-09-28 16:27:14,457 INFO image_writer.py:197 - writing: sitkImage\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf514e00ee24ca7bd68ff888ccbb24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x103f0c3f0)\n",
      "  RTTI typeinfo:   itk::Image<unsigned short, 2u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 18138\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 18125\n",
      "  UpdateMTime: 18137\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 2\n",
      "    Index: [0, 0]\n",
      "    Size: [192, 3]\n",
      "  BufferedRegion: \n",
      "    Dimension: 2\n",
      "    Index: [0, 0]\n",
      "    Size: [192, 3]\n",
      "  RequestedRegion: \n",
      "    Dimension: 2\n",
      "    Index: [0, 0]\n",
      "    Size: [192, 3]\n",
      "  Spacing: [1.17188, 3.6]\n",
      "  Origin: [18.4, 112.5]\n",
      "  Direction: \n",
      "0 1\n",
      "-1 0\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0 3.6\n",
      "-1.17188 0\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "0 -0.853333\n",
      "0.277778 0\n",
      "\n",
      "  Inverse Direction: \n",
      "0 -1\n",
      "1 0\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x2b8510f50)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, unsigned short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 18135\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x2a6a26800\n",
      "      Container manages memory: true\n",
      "      Size: 576\n",
      "      Capacity: 576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test ImageLoad\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n",
    "\n",
    "# Make list with two images filenames\n",
    "data_list = [train_files[0]['image_1'], train_files[0]['image_2']]\n",
    "\n",
    "load_file = Compose([LoadImage(image_only=True), EnsureChannelFirst(channel_dim='no_channel'), PushSitkImage(resample=False, output_dtype=np.float32)])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "show_image(output_original[0])\n",
    "print((output_original[0][1])) # See metatensor for first output\n",
    "# print((output_original[0][1])) # See dictionary for first output\n",
    "\n",
    "# metatensor_1 = output_original[0][0]\n",
    "# metatensor_2 = output_original[1][0]\n",
    "# print(metatensor_1.data.shape)\n",
    "# print(metatensor_1.data[0,0])\n",
    "# print(metatensor_2.data[0,0])\n",
    "\n",
    "# # LOAD WITH ITK IMAGE LOADER TO COMPARE\n",
    "# itk_image_1 = itk.imread(train_files[0]['image_1']).astype(itk.F)\n",
    "# itk_image_2 = itk.imread(train_files[0]['image_2']).astype(itk.F)\n",
    "\n",
    "# # Make list with two itk image objects\n",
    "# data_list = [itk_image_1, itk_image_2]\n",
    "\n",
    "# load_itk = Compose([LoadITKImage()])\n",
    "# output_original = load_itk(data_list)\n",
    "# metatensor_1 = output_original[0][0]\n",
    "# metatensor_2 = output_original[1][0]\n",
    "# print(metatensor_1.data.shape)\n",
    "# print(metatensor_1.data[0,0])\n",
    "# print(metatensor_2.data[0,0])\n",
    "\n",
    "# TEST NEW CUSTOM SITK LOADER\n",
    "# sitk_image_1 = sitk.ReadImage(train_files[0]['image_1'], sitk.sitkFloat32)\n",
    "# sitk_image_2 = sitk.ReadImage(train_files[0]['image_2'], sitk.sitkFloat32)\n",
    "\n",
    "# # Make list with two sitk image objectss\n",
    "# data_list = [sitk_image_1, sitk_image_2]\n",
    "\n",
    "# load_sitk = Compose([LoadSitkImage(image_only=True), EnsureChannelFirst(channel_dim='no_channel')])\n",
    "# output_original = load_sitk(data_list)\n",
    "# metatensor_1 = output_original[0][0]\n",
    "# metatensor_2 = output_original[1][0]\n",
    "# print(metatensor_1.data.shape)\n",
    "# print(metatensor_1.data[0,0])\n",
    "# print(metatensor_2.data[0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled images from: /Users/pl771/Devel/MRINeedleSegmentation/TestingNotebook\n",
      "Use magnitude/phase images\n",
      "Image_1 - Mag\n",
      "torch.Size([1, 192, 192, 3])\n",
      "metatensor([0.0128, 0.0043, 0.0085])\n",
      "metatensor([0.0279, 0.0708, 0.0445])\n",
      "Image_2 - Phase\n",
      "torch.Size([1, 192, 192, 3])\n",
      "metatensor([-1.4955, -1.9595, -1.1875])\n",
      "metatensor([-0.5207,  1.2078,  0.7674])\n"
     ]
    }
   ],
   "source": [
    "# Test ImageLoadd\n",
    "data_list = generateLabeledFileList(param, 'test')\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "\n",
    "load_file = Compose([LoadImaged(keys=['image_1', 'image_2'], image_only=False), EnsureChannelFirstd(keys=[\"image_1\", \"image_2\"])])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "\n",
    "metatensor_1 = output_original[0]['image_1']\n",
    "metatensor_2 = output_original[1]['image_1']\n",
    "\n",
    "print('Image_1 - Mag')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0,0])\n",
    "print(metatensor_2.data[0,0,1])\n",
    "\n",
    "metatensor_1 = output_original[0]['image_2']\n",
    "metatensor_2 = output_original[1]['image_2']\n",
    "\n",
    "print('Image_2 - Phase')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0,0])\n",
    "print(metatensor_2.data[0,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_1 - Mag\n",
      "torch.Size([1, 192, 192, 3])\n",
      "metatensor([0.0128, 0.0043, 0.0085])\n",
      "metatensor([0.0279, 0.0708, 0.0445])\n",
      "Image_2 - Phase\n",
      "torch.Size([1, 192, 192, 3])\n",
      "metatensor([[-1.4955e+00, -1.9595e+00, -1.1875e+00],\n",
      "        [-1.2804e+00, -2.2942e+00, -8.5895e-01],\n",
      "        [-8.7988e-01, -1.9479e+00, -9.1828e-01],\n",
      "        [-4.5741e-01, -8.8338e-03, -9.7589e-01],\n",
      "        [ 4.8468e-01,  5.9990e-01,  1.1276e+00],\n",
      "        [ 1.1238e+00,  9.3384e-01,  1.7935e-01],\n",
      "        [ 1.4736e+00,  3.3797e-01, -2.4080e+00],\n",
      "        [ 1.5262e+00, -2.9937e-01, -7.1800e-01],\n",
      "        [ 1.0408e+00, -3.1877e-01,  1.8673e+00],\n",
      "        [ 2.6442e-01, -8.8314e-01,  2.1565e+00],\n",
      "        [ 9.4133e-01, -1.4091e+00,  1.5351e+00],\n",
      "        [ 1.3250e+00, -2.0751e+00,  7.3912e-01],\n",
      "        [ 1.2313e+00, -2.3573e+00,  1.1022e+00],\n",
      "        [ 1.6764e-01, -2.5215e+00,  1.6376e+00],\n",
      "        [-9.7973e-01, -2.4234e+00,  1.1614e+00],\n",
      "        [-1.2975e+00, -2.0119e+00,  2.4330e-01],\n",
      "        [-7.4968e-01, -1.4325e+00,  5.5612e-01],\n",
      "        [ 4.2784e-01, -9.8914e-01,  1.2668e+00],\n",
      "        [ 2.2248e+00, -1.2029e+00,  1.4391e+00],\n",
      "        [ 5.5093e-01, -1.5600e+00,  1.5727e+00],\n",
      "        [-2.2644e+00, -1.8473e+00,  1.9180e+00],\n",
      "        [-1.3751e+00, -1.9389e+00,  1.4087e+00],\n",
      "        [ 1.2881e+00, -1.9844e+00,  8.3033e-01],\n",
      "        [-2.4829e-01, -2.1348e+00,  6.9553e-01],\n",
      "        [ 2.7975e+00,  2.4119e+00,  7.6965e-01],\n",
      "        [-4.6068e-01,  2.0879e+00,  1.0986e+00],\n",
      "        [ 5.2040e-01,  2.1953e+00,  1.2052e+00],\n",
      "        [ 8.0902e-01,  1.0548e+00,  6.8439e-01],\n",
      "        [ 5.1156e-01,  2.3811e-02, -1.6975e-01],\n",
      "        [-6.6231e-01, -1.4404e+00, -6.4234e-01],\n",
      "        [-1.5746e+00, -1.2420e+00,  1.0550e+00],\n",
      "        [-2.6241e+00, -8.0748e-01,  2.2679e+00],\n",
      "        [-3.2415e-01,  2.9880e-01,  2.4987e+00],\n",
      "        [ 1.4287e+00,  1.0454e+00,  2.4201e+00],\n",
      "        [-6.7210e-02,  3.7446e-01,  2.3312e+00],\n",
      "        [ 7.7003e-02,  1.5159e+00,  1.2722e+00],\n",
      "        [-1.4748e+00,  1.9026e+00,  1.0969e+00],\n",
      "        [-3.5621e-01,  1.3146e+00, -1.0949e+00],\n",
      "        [ 4.6740e-01,  1.8051e-01,  8.9101e-02],\n",
      "        [ 7.0513e-01,  5.3384e-01, -1.6084e+00],\n",
      "        [-1.9802e+00, -3.0955e-01, -1.1445e-01],\n",
      "        [ 3.7676e-01,  1.6480e+00, -4.3610e-01],\n",
      "        [ 7.3662e-01, -8.3648e-01, -1.1579e+00],\n",
      "        [ 2.5943e-01, -8.6106e-01,  9.6322e-01],\n",
      "        [-2.7783e+00,  1.6146e+00,  1.2290e+00],\n",
      "        [ 4.2957e-01,  1.2399e+00,  8.3437e-01],\n",
      "        [ 6.0681e-02,  1.0554e+00,  1.0450e+00],\n",
      "        [ 1.9662e+00,  1.4959e-01,  1.6584e+00],\n",
      "        [ 6.7978e-01, -6.9438e-01,  2.0117e+00],\n",
      "        [ 2.9361e-01,  1.4652e+00,  1.9468e+00],\n",
      "        [-9.6552e-01, -7.1012e-01,  8.3686e-01],\n",
      "        [-1.8283e+00, -8.3686e-01, -3.7330e-01],\n",
      "        [ 4.2016e-01, -1.3150e+00, -5.9222e-01],\n",
      "        [-1.1791e-01, -1.6737e+00, -6.9111e-01],\n",
      "        [ 7.7080e-01, -2.0897e+00, -4.6548e-01],\n",
      "        [ 1.1364e+00,  5.0503e-02, -1.2186e+00],\n",
      "        [-3.8329e-01,  7.3662e-01, -1.3450e+00],\n",
      "        [-1.6311e+00,  4.2189e-01,  7.1434e-02],\n",
      "        [-1.0792e-01, -7.1435e-02,  4.6240e-01],\n",
      "        [ 1.2534e+00, -6.7018e-02,  8.9946e-01],\n",
      "        [ 8.6797e-01,  1.3619e+00,  9.6783e-01],\n",
      "        [ 7.2990e-01,  1.8644e+00,  6.1718e-01],\n",
      "        [ 5.3384e-01,  1.0151e+00,  4.3936e-01],\n",
      "        [ 5.8665e-01, -1.5170e-01,  8.8717e-02],\n",
      "        [-1.7482e+00, -6.4215e-01, -4.3859e-01],\n",
      "        [ 8.0883e-01, -9.8895e-02, -3.7138e-01],\n",
      "        [ 8.3341e-01,  1.7613e+00,  2.9304e-01],\n",
      "        [ 1.0562e+00,  1.2929e+00, -1.5497e-01],\n",
      "        [ 2.2429e-01,  8.0191e-01, -1.1998e+00],\n",
      "        [-1.1881e+00, -1.4921e-01, -9.5266e-01],\n",
      "        [-5.5112e-01, -6.0220e-01,  7.3278e-01],\n",
      "        [ 1.1406e-01, -1.0973e+00,  9.9068e-01],\n",
      "        [ 7.2971e-01, -1.4433e+00,  2.5425e-01],\n",
      "        [ 1.2674e-01, -1.7440e+00,  2.4445e-01],\n",
      "        [ 2.2851e-01,  4.4013e-01,  1.2029e+00],\n",
      "        [-2.3946e-01,  2.7009e+00,  1.3087e+00],\n",
      "        [ 8.3725e-01,  2.4426e+00,  7.1358e-01],\n",
      "        [ 1.0379e+00,  1.6495e-01, -1.3922e-01],\n",
      "        [ 1.7943e+00, -6.0988e-01, -1.8546e+00],\n",
      "        [ 7.7637e-01, -1.9856e+00,  1.0715e+00],\n",
      "        [ 8.8026e-01,  1.9817e-01,  1.5585e+00],\n",
      "        [-4.4128e-01, -5.9951e-01,  4.9159e-01],\n",
      "        [-8.4531e-01, -2.0685e+00,  8.9946e-01],\n",
      "        [-1.6077e+00, -2.1181e+00, -1.4055e+00],\n",
      "        [-2.3827e+00,  7.8732e-01, -1.2858e+00],\n",
      "        [ 7.6869e-01,  8.8986e-01,  5.5112e-01],\n",
      "        [ 9.1598e-01,  7.9654e-01,  8.0614e-01],\n",
      "        [ 5.4191e-01, -7.5199e-01,  6.8497e-01],\n",
      "        [-1.9049e-01, -1.6945e+00, -2.2360e+00],\n",
      "        [-6.8305e-01, -1.1625e+00, -1.0686e+00],\n",
      "        [-1.1729e+00,  2.0393e-01,  1.2025e+00],\n",
      "        [-7.5141e-01, -7.3682e-01, -1.1887e-01],\n",
      "        [-1.2344e+00, -4.4474e-01, -2.0662e-01],\n",
      "        [ 9.6379e-01, -6.0796e-01, -9.6110e-01],\n",
      "        [-3.8790e-01, -7.1358e-01,  1.4402e+00],\n",
      "        [-1.7010e+00, -4.1709e-01,  1.6553e+00],\n",
      "        [-2.0148e+00, -8.0959e-01,  1.4418e+00],\n",
      "        [ 6.9995e-01, -4.4436e-01,  3.5986e-01],\n",
      "        [-3.6831e-01,  1.2643e+00, -1.0350e+00],\n",
      "        [-2.1411e-01,  6.3408e-01, -7.0571e-01],\n",
      "        [ 2.0125e-01,  3.3106e-01,  5.8991e-01],\n",
      "        [ 5.2597e-01, -4.9928e-01,  7.7388e-01],\n",
      "        [ 8.2841e-01, -2.3558e+00,  1.2854e+00],\n",
      "        [ 1.1234e-01, -7.6216e-01,  4.5127e-02],\n",
      "        [ 9.4478e-01, -2.1730e+00, -1.2597e-01],\n",
      "        [-4.9928e-02, -2.3389e-01,  2.7614e-01],\n",
      "        [ 4.0787e-01, -6.6826e-01,  5.3422e-01],\n",
      "        [ 6.4042e-01,  1.5324e+00,  5.9299e-01],\n",
      "        [ 2.0601e+00,  1.6906e+00,  3.0264e-01],\n",
      "        [ 1.2920e+00, -6.5789e-01,  7.3854e-01],\n",
      "        [ 5.4997e-01,  4.1862e-02,  1.0592e+00],\n",
      "        [ 8.8468e-01,  2.2878e+00,  7.7676e-01],\n",
      "        [-1.2912e+00,  2.7675e+00,  2.7268e-01],\n",
      "        [-5.5112e-01,  2.4983e-01,  4.9639e-01],\n",
      "        [-1.2328e-01,  4.4666e-01,  6.9591e-01],\n",
      "        [-5.6649e-02,  4.9543e-02,  1.4421e-01],\n",
      "        [-2.2276e-02, -2.3812e-01, -7.8041e-01],\n",
      "        [ 1.4767e-01, -1.2649e+00, -2.2660e-02],\n",
      "        [ 7.5198e-01, -9.8319e-01,  3.7599e-01],\n",
      "        [-8.6451e-01,  1.1022e-01,  3.3220e-02],\n",
      "        [-1.2490e+00,  1.4049e+00, -3.3106e-01],\n",
      "        [-1.5871e+00,  2.2091e+00, -4.4936e-02],\n",
      "        [-1.3550e+00,  1.9760e+00,  1.2021e-01],\n",
      "        [-5.1851e-03,  5.8665e-01, -1.5045e+00],\n",
      "        [ 8.1343e-01,  1.1214e+00, -1.8081e+00],\n",
      "        [ 1.0337e+00,  1.8757e+00,  1.0323e+00],\n",
      "        [ 9.7704e-01,  1.6442e+00,  1.8216e+00],\n",
      "        [ 4.6471e-01,  1.8204e-01, -2.5521e-01],\n",
      "        [ 1.7897e-01, -9.5861e-01,  1.1138e-01],\n",
      "        [-6.0547e-01, -1.6555e+00,  2.7863e-01],\n",
      "        [-1.4498e+00, -1.8366e+00, -1.1756e+00],\n",
      "        [-2.4065e+00,  4.1459e-01, -1.4373e+00],\n",
      "        [ 2.9672e+00,  1.1506e+00, -1.3373e+00],\n",
      "        [ 2.3652e+00,  1.1929e+00, -7.5371e-01],\n",
      "        [ 2.2083e+00,  1.3446e+00,  2.9150e-01],\n",
      "        [ 2.9380e-02,  1.6916e+00,  1.2019e+00],\n",
      "        [-1.5224e+00,  2.0754e+00,  1.7298e+00],\n",
      "        [ 3.0801e-01, -2.7775e+00,  5.5554e-01],\n",
      "        [-1.0370e+00, -2.6508e+00, -4.2631e-02],\n",
      "        [ 8.2569e-03, -7.4334e-01, -4.7546e-01],\n",
      "        [-2.2437e+00, -1.0746e+00, -6.7364e-01],\n",
      "        [-1.2042e+00, -2.1304e+00, -2.9572e-01],\n",
      "        [-6.4138e-01, -1.3457e+00, -1.9575e+00],\n",
      "        [-6.3619e-01,  2.0549e+00, -1.2217e+00],\n",
      "        [-8.9102e-02, -7.8501e-01,  1.2781e+00],\n",
      "        [-2.2237e-01, -8.8487e-01,  1.3089e+00],\n",
      "        [ 1.7859e-01, -7.0398e-01, -2.6692e-01],\n",
      "        [-9.1252e-01, -3.0821e-01,  1.2918e+00],\n",
      "        [-8.8487e-01, -2.6116e-01,  1.8719e+00],\n",
      "        [-5.5861e-01,  8.3552e-01,  1.2747e+00],\n",
      "        [-1.2309e+00,  1.2674e-02, -4.4128e-01],\n",
      "        [ 1.4306e-01, -7.2606e-01,  3.7637e-02],\n",
      "        [ 3.2799e-01, -5.3615e-01, -3.7945e-01],\n",
      "        [-4.7892e-01, -4.8814e-01,  1.3749e+00],\n",
      "        [ 5.4767e-01, -8.9140e-01, -5.8262e-01],\n",
      "        [ 1.5109e+00, -1.2198e+00, -3.3029e-01],\n",
      "        [ 4.7239e-01, -1.3035e+00, -3.2184e-01],\n",
      "        [ 1.6322e-01, -3.8809e-01, -2.6433e+00],\n",
      "        [-3.7215e-01,  3.8137e-01, -1.5251e+00],\n",
      "        [-3.7868e-01,  5.3096e-01, -8.8103e-01],\n",
      "        [-1.2444e-01,  3.8636e-01, -1.0646e+00],\n",
      "        [-1.6476e-01,  7.3336e-01,  1.4183e+00],\n",
      "        [-4.8046e-01,  1.6979e+00, -1.8089e-01],\n",
      "        [-8.8890e-01,  7.7580e-01, -1.6678e+00],\n",
      "        [-1.4425e+00,  7.8271e-01, -1.7897e-01],\n",
      "        [-1.8679e+00, -1.6190e+00, -7.9519e-01],\n",
      "        [-7.0705e-01, -3.1454e-01, -2.1043e+00],\n",
      "        [ 6.4330e-01, -1.8876e-01, -2.3170e+00],\n",
      "        [ 8.4877e-01, -9.4939e-01, -2.4480e+00],\n",
      "        [-1.7413e+00, -1.1917e+00, -2.5813e+00],\n",
      "        [-1.2716e+00, -4.5857e-01, -2.7618e+00],\n",
      "        [-1.2432e+00, -3.8848e-01, -2.7199e+00],\n",
      "        [-1.3181e+00, -6.6058e-01, -2.2352e+00],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [ 3.1416e+00, -3.5763e-07, -3.5763e-07],\n",
      "        [ 3.1416e+00, -3.5763e-07,  3.1416e+00],\n",
      "        [-3.5763e-07,  3.1416e+00, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07,  3.1416e+00],\n",
      "        [ 3.1416e+00, -3.5763e-07, -3.5763e-07],\n",
      "        [ 3.1416e+00, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07,  3.1416e+00, -3.5763e-07],\n",
      "        [-3.5763e-07,  3.1416e+00, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [ 3.1416e+00, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07,  3.1416e+00, -3.5763e-07],\n",
      "        [ 3.1416e+00, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07, -3.5763e-07],\n",
      "        [-3.5763e-07, -3.5763e-07,  3.1416e+00]])\n",
      "metatensor([[ 0.3028,  1.0353,  0.3683],\n",
      "        [-0.5207,  1.2078,  0.7674],\n",
      "        [ 1.3040,  1.7189,  1.6523],\n",
      "        [ 1.4685,  2.3031,  1.2632],\n",
      "        [-2.3890,  1.2635, -2.3864],\n",
      "        [-2.3201, -2.6655, -2.4607],\n",
      "        [-2.1881, -2.3917, -2.3970],\n",
      "        [-2.1688, -2.2865, -2.4222],\n",
      "        [-2.2124, -2.3172, -2.4762],\n",
      "        [-2.2743, -2.4492, -2.4884],\n",
      "        [-2.3131, -2.5673, -2.4741],\n",
      "        [-2.3559, -2.6294, -2.5305],\n",
      "        [-2.5321, -2.7245, -2.4939],\n",
      "        [-1.1095, -1.0665, -0.0356],\n",
      "        [ 2.5719,  2.7512,  2.5114],\n",
      "        [ 2.2940,  2.4158,  2.4339],\n",
      "        [ 2.3205,  2.4368,  2.5726],\n",
      "        [ 2.3849,  2.4736,  2.6697],\n",
      "        [ 2.3790,  2.3923,  2.6352],\n",
      "        [ 2.3702,  2.3046,  2.5154],\n",
      "        [ 2.3779,  2.2916,  2.3689],\n",
      "        [ 2.3416,  2.2893,  2.2650],\n",
      "        [ 2.2383,  2.2249,  2.2529],\n",
      "        [ 2.1524,  2.1300,  2.3087],\n",
      "        [ 2.1439,  2.0912,  2.3536],\n",
      "        [ 2.1532,  2.1223,  2.3573],\n",
      "        [ 2.1260,  2.1702,  2.3872],\n",
      "        [ 2.0920,  2.2296,  2.4606],\n",
      "        [ 2.0741,  2.3021,  2.4752],\n",
      "        [ 2.0039,  2.3170,  2.2786],\n",
      "        [ 1.8212,  2.1575,  1.9320],\n",
      "        [ 1.6565,  1.9599,  1.6790],\n",
      "        [ 1.7254,  2.0079,  1.7525],\n",
      "        [ 2.2105,  2.3121,  2.2159],\n",
      "        [ 2.5579,  2.5607,  2.6159],\n",
      "        [ 2.5174,  2.6189,  2.7028],\n",
      "        [ 2.3318,  2.5508,  2.5548],\n",
      "        [ 1.9645,  2.3271,  2.2779],\n",
      "        [ 1.5902,  2.0099,  2.1345],\n",
      "        [ 1.5076,  1.8742,  2.1417],\n",
      "        [ 1.5950,  1.9247,  2.1727],\n",
      "        [ 1.6785,  1.9826,  2.1583],\n",
      "        [ 1.6671,  1.9506,  2.0699],\n",
      "        [ 1.5358,  1.8510,  1.8980],\n",
      "        [ 1.2971,  1.7020,  1.7535],\n",
      "        [ 1.1070,  1.5120,  1.7379],\n",
      "        [ 1.1002,  1.3566,  1.7865],\n",
      "        [ 1.2210,  1.3120,  1.8191],\n",
      "        [ 1.2910,  1.3838,  1.7923],\n",
      "        [ 1.1907,  1.4836,  1.6755],\n",
      "        [ 0.9958,  1.5040,  1.3612],\n",
      "        [ 0.8215,  1.2782,  0.9026],\n",
      "        [ 0.6821,  0.7910,  0.7242],\n",
      "        [ 0.6059,  0.6350,  0.7397],\n",
      "        [ 0.6331,  0.7969,  0.7941],\n",
      "        [ 0.7112,  0.8938,  0.7908],\n",
      "        [ 0.6707,  0.8226,  0.7327],\n",
      "        [ 0.3971,  0.5627,  0.7032],\n",
      "        [-0.0161,  0.2409,  0.6965],\n",
      "        [-0.3627,  0.0616,  0.5517],\n",
      "        [-0.5777, -0.0946,  0.1726],\n",
      "        [-0.7331, -0.3861, -0.3053],\n",
      "        [-0.8981, -0.7203, -0.6622],\n",
      "        [-1.0852, -0.9383, -0.9077],\n",
      "        [-1.2524, -1.0237, -1.1040],\n",
      "        [-1.3886, -1.0882, -1.2613],\n",
      "        [-1.5067, -1.1939, -1.3595],\n",
      "        [-1.6258, -1.3493, -1.4149],\n",
      "        [-1.7208, -1.4978, -1.4556],\n",
      "        [-1.7554, -1.5920, -1.5131],\n",
      "        [-1.7550, -1.6672, -1.6344],\n",
      "        [-1.7689, -1.7561, -1.8133],\n",
      "        [-1.7656, -1.8215, -1.9162],\n",
      "        [-1.6875, -1.8013, -1.9000],\n",
      "        [-1.5769, -1.7282, -1.8542],\n",
      "        [-1.5239, -1.6208, -1.9028],\n",
      "        [-1.5142, -1.4539, -2.1165],\n",
      "        [-1.4462, -1.2753, -2.0093],\n",
      "        [-1.3142, -1.0295,  0.8940],\n",
      "        [-1.1887, -0.6179,  1.0876],\n",
      "        [-1.0462, -0.1569,  0.6968],\n",
      "        [-0.8515,  0.0322, -0.1231],\n",
      "        [-0.5736, -0.0169, -0.2537],\n",
      "        [-0.2448, -0.0726, -0.3686],\n",
      "        [ 0.0816,  0.0386, -0.3563],\n",
      "        [ 0.3243,  0.2665, -0.0874],\n",
      "        [ 0.5110,  0.5336,  0.3853],\n",
      "        [ 0.7092,  0.7459,  0.8758],\n",
      "        [ 0.9569,  1.1414,  1.5991],\n",
      "        [ 1.2096,  2.0208,  2.3024],\n",
      "        [ 1.3670,  2.5217,  2.8599],\n",
      "        [ 1.3822,  2.6142,  1.1670],\n",
      "        [ 1.3309,  2.5252, -0.2532],\n",
      "        [ 1.2281,  2.4540,  3.0279],\n",
      "        [ 1.0437,  2.3607,  2.8590],\n",
      "        [ 0.8358,  2.1757,  2.5753],\n",
      "        [ 0.5822,  1.8527,  2.4012],\n",
      "        [ 0.2368,  1.4566,  2.5097],\n",
      "        [-0.0769,  0.6882,  2.7129],\n",
      "        [-0.3169, -0.2497,  0.3614],\n",
      "        [-0.5755, -0.7439, -0.5428],\n",
      "        [-0.8576, -1.0777,  0.0307],\n",
      "        [-1.0976, -1.4056, -0.0679],\n",
      "        [-1.2942, -1.5678, -0.5664],\n",
      "        [-1.4406, -1.6739, -0.8027],\n",
      "        [-1.5049, -1.6996, -1.1615],\n",
      "        [-1.5813, -1.8008, -1.7984],\n",
      "        [-1.7646, -2.0957, -2.3087],\n",
      "        [-2.0566, -2.4332, -2.4837],\n",
      "        [-2.3444, -2.5858, -2.5031],\n",
      "        [-2.5190, -2.6548, -2.4984],\n",
      "        [-2.6766, -2.7756, -1.1231],\n",
      "        [-1.8955, -1.9294,  1.0777],\n",
      "        [ 1.6904, -1.1623,  0.9274],\n",
      "        [ 2.7492, -1.2037,  2.4318],\n",
      "        [ 2.5776, -1.3290,  2.3923],\n",
      "        [ 2.5138,  2.7052,  2.1838],\n",
      "        [ 2.4823,  2.3797,  2.1234],\n",
      "        [ 2.4011,  2.2499,  2.1339],\n",
      "        [ 2.2958,  2.2291,  2.1700],\n",
      "        [ 2.2039,  2.2272,  2.2069],\n",
      "        [ 2.1602,  2.2662,  2.2720],\n",
      "        [ 2.1515,  2.3440,  2.3565],\n",
      "        [ 2.1628,  2.4161,  2.3061],\n",
      "        [ 2.2358,  2.4796,  2.0451],\n",
      "        [ 2.4269,  2.5479,  1.8217],\n",
      "        [ 2.6850,  2.5510,  1.7907],\n",
      "        [ 2.8580,  2.4405,  1.8053],\n",
      "        [ 2.8677,  2.2216,  1.7289],\n",
      "        [ 2.8069,  1.8908,  1.5451],\n",
      "        [ 2.7842,  1.6527,  1.3082],\n",
      "        [ 2.7711,  1.5544,  1.0456],\n",
      "        [ 2.7028,  1.5542,  0.7124],\n",
      "        [ 2.5840,  1.6227,  0.4509],\n",
      "        [ 2.4726,  1.6702,  0.4537],\n",
      "        [ 2.4359,  1.6495,  0.6435],\n",
      "        [ 2.4538,  1.5971,  0.8107],\n",
      "        [ 2.4171,  1.4709,  1.0026],\n",
      "        [ 2.2785,  1.2703,  1.2500],\n",
      "        [ 2.0604,  1.0523,  1.0762],\n",
      "        [ 1.8193,  0.9363,  0.6116],\n",
      "        [ 1.6199,  1.0746,  0.4481],\n",
      "        [ 1.5560,  1.6534,  1.2191],\n",
      "        [ 1.7628,  2.1721,  1.9343],\n",
      "        [ 2.1326,  2.3245,  2.0104],\n",
      "        [ 2.3484,  2.2885,  2.0840],\n",
      "        [ 2.3479,  2.1677,  2.0964],\n",
      "        [ 2.2191,  2.0000,  1.8083],\n",
      "        [ 2.0382,  1.7626,  0.9520],\n",
      "        [ 1.7994,  1.5152,  0.4662],\n",
      "        [ 1.4913,  1.4589,  0.5920],\n",
      "        [ 1.3214,  1.5843,  0.8277],\n",
      "        [ 1.4307,  1.6104,  0.7575],\n",
      "        [ 1.5530,  1.3705,  0.4221],\n",
      "        [ 1.3702,  0.8554,  0.1140],\n",
      "        [ 0.2603,  0.4949,  0.1934],\n",
      "        [-0.1780,  0.4603,  0.4252],\n",
      "        [ 0.2096,  0.5158,  0.5717],\n",
      "        [ 0.6729,  0.6050,  0.7005],\n",
      "        [ 1.0141,  0.7383,  0.8453],\n",
      "        [ 1.2891,  0.9207,  1.1243],\n",
      "        [ 1.5126,  1.3867,  2.0004],\n",
      "        [ 1.9553,  2.1458,  2.4774],\n",
      "        [ 2.5574,  2.2769,  2.3044],\n",
      "        [ 2.6823,  2.1105,  2.0379],\n",
      "        [ 2.7257,  2.2120,  2.1922],\n",
      "        [-0.4084, -2.2040,  2.9255],\n",
      "        [-2.4612, -2.7612, -3.0780],\n",
      "        [-2.4185, -2.7522, -3.0643],\n",
      "        [-2.4419, -2.7339, -3.0139],\n",
      "        [-2.4454, -2.6938, -2.9392],\n",
      "        [-2.4962, -2.7004, -2.8662],\n",
      "        [-2.6328, -2.7952, -2.8458],\n",
      "        [-2.8168, -2.9565, -2.9244],\n",
      "        [-2.5804,  1.3192,  1.2100],\n",
      "        [ 2.3007,  2.6980,  1.1232],\n",
      "        [ 0.4101,  1.4435,  1.4899],\n",
      "        [-0.6587, -0.3137,  0.1735],\n",
      "        [-1.1266,  1.2405, -1.3000],\n",
      "        [-0.6985,  2.1501, -2.0242],\n",
      "        [-0.5752,  2.4178,  0.0588],\n",
      "        [ 1.9501,  2.8487,  1.2807],\n",
      "        [ 2.2100,  2.3842,  1.8719],\n",
      "        [ 0.8238,  1.2360,  1.4713],\n",
      "        [-1.1998,  1.0880,  1.0378],\n",
      "        [ 1.8016,  1.0981,  1.1997],\n",
      "        [ 1.7123,  1.9879,  1.1058],\n",
      "        [ 1.4390,  1.0902,  1.3435],\n",
      "        [ 0.8962,  0.3316, -0.8028],\n",
      "        [ 0.8513,  0.0240, -0.6390],\n",
      "        [ 1.5882, -0.5276, -0.5887],\n",
      "        [ 1.7935, -0.7971, -0.0836]])\n"
     ]
    }
   ],
   "source": [
    "# Test sitkLoadD\n",
    "prefix = 'test'\n",
    "images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "\n",
    "data_list = []\n",
    "for image_m_name, image_p_name in zip(images_m, images_p):\n",
    "    sitk_image_1 = sitk.ReadImage(image_m_name, sitk.sitkFloat32)\n",
    "    sitk_image_2 = sitk.ReadImage(image_p_name, sitk.sitkFloat32)\n",
    "    data_list.append({\"image_1\": sitk_image_1, \"image_2\": sitk_image_2,})\n",
    "\n",
    "# Take just one pair (last one)\n",
    "# data_list = [{'image_1': sitk_image_1, 'image_2': sitk_image_2}]\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "\n",
    "load_file = Compose([LoadSitkImaged(keys=['image_1', 'image_2'], image_only=False), EnsureChannelFirstd(keys=[\"image_1\", \"image_2\"])])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "\n",
    "metatensor_1 = output_original[0]['image_1']\n",
    "metatensor_2 = output_original[1]['image_1']\n",
    "\n",
    "# print('Image_1 - Mag')\n",
    "# print(metatensor_1.data.shape)\n",
    "# print(metatensor_1.data[0,0,0])\n",
    "# print(metatensor_2.data[0,0,1])\n",
    "\n",
    "# metatensor_1 = output_original[0]['image_2']\n",
    "# metatensor_2 = output_original[1]['image_2']\n",
    "\n",
    "# print('Image_2 - Phase')\n",
    "# print(metatensor_1.data.shape)\n",
    "# print(metatensor_1.data[0,0,0])\n",
    "# print(metatensor_2.data[0,0,1])\n",
    "\n",
    "\n",
    "load_file = Compose([LoadSitkImaged(keys=['image_1', 'image_2'], image_only=False), EnsureChannelFirstd(keys=[\"image_1\", \"image_2\"])])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_transform = Compose([LoadSitkImaged(keys=[\"image_1\", \"image_2\"]), EnsureChannelFirstd(keys=[\"image_1\", \"image_2\"])])\n",
    "output_original = inference_transform(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transforms\n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\")\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "    ]\n",
    "    \n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))\n",
    "    transform_array.append(ScaleIntensityd(keys=[\"image\", \"label\"], minv=0, maxv=1, channel_wise=True))\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\")))\n",
    "\n",
    "# Plot original\n",
    "loadTest = Compose(transform_array)\n",
    "output_original = loadTest(train_files)\n",
    "\n",
    "for i in range(len(output_original)):\n",
    "    if len(output_original)==1:\n",
    "        output_dict = output_original[0]\n",
    "    else:\n",
    "        output_dict = output_original[0][i]\n",
    "    # output_dict = output[0]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    # image = output_dict[0]['image']\n",
    "    # label = output_dict[0]['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 Original')\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 Original')\n",
    "    show_array(label_array[0,:,:,:], title='Label Original')\n",
    "\n",
    "# Data augmentation\n",
    "transform_array.append(RandZoomd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.1,\n",
    "    min_zoom=1.0,\n",
    "    max_zoom=1.3,\n",
    "    mode=['area', 'nearest'],\n",
    "))\n",
    "transform_array.append(RandFlipd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.5,\n",
    "    spatial_axis=2,\n",
    "))\n",
    "# Balance background/foreground\n",
    "transform_array.append(RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=param.window_size,\n",
    "    pos=5, \n",
    "    neg=1,\n",
    "    num_samples=5,\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0, \n",
    "))\n",
    "\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "N = len(output[0])\n",
    "for i in range(N):\n",
    "    output_dict = output[0][i]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 '+ str(i+1))\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 '+ str(i+1))\n",
    "    show_array(label_array[0,:,:,:], title='Label '+ str(i+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import UNet\n",
    "\n",
    "# # Define the UNet architecture\n",
    "# model_unet = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=[16, 32, 64, 128],\n",
    "#     strides=[(1, 2, 2), (1, 2, 2), (1, 1, 1)],\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "\n",
    "# # Create an example input tensor\n",
    "# input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# # Pass the input tensor through the UNet model\n",
    "# output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# # Print the size of the output tensor\n",
    "# print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
