{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, ensure_tuple\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.label_type = label_type\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_\"+param.label_type+\"_label.nii.gz\")))\n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()\n",
    "pixel_dim = (3.6, 1.171875, 1.171875)\n",
    "window_size = (3, 48, 48)\n",
    "orientation = 'PIL'\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "input_type = 'MP'\n",
    "label_type = 'multi'\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW CUSTOM ITK OBJECT LOADER\n",
    "\n",
    "from collections.abc import Sequence\n",
    "import SimpleITK as sitk\n",
    "from monai.data import MetaTensor, ImageReader, ITKReader\n",
    "from monai.data.utils import orientation_ras_lps, is_no_channel\n",
    "import torch\n",
    "from monai.config import DtypeLike, PathLike, KeysCollection\n",
    "from monai.utils import convert_to_dst_type, ensure_tuple, ensure_tuple_rep, MetaKeys, SpaceKeys, TraceKeys\n",
    "from monai.utils import ImageMetaKey as Key\n",
    "from torch.utils.data._utils.collate import np_str_obj_array_pattern\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from monai.transforms import Compose, Transform, MapTransform\n",
    "from monai.utils.enums import PostFix\n",
    "DEFAULT_POST_FIX = PostFix.meta()\n",
    "\n",
    "class sitkReader(ImageReader):\n",
    "    def __init__(\n",
    "            self,\n",
    "            series_name: str = \"\",\n",
    "            reverse_indexing: bool = False,\n",
    "            series_meta: bool = False,\n",
    "            affine_lps_to_ras: bool = True,\n",
    "            **kwargs,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.series_name = series_name\n",
    "        self.reverse_indexing = reverse_indexing\n",
    "        self.series_meta = series_meta\n",
    "        self.affine_lps_to_ras = affine_lps_to_ras\n",
    "    \n",
    "    def read(self, img):\n",
    "        return img\n",
    "    \n",
    "    def verify_suffix(self, img) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def get_data(self, img) -> tuple[np.ndarray, dict]:\n",
    "        img_array: list[np.ndarray] = []\n",
    "        compatible_meta: dict = {}\n",
    "        data = self._get_array_data(img)\n",
    "        img_array.append(data)\n",
    "        header = self._get_meta_dict(img)\n",
    "        header[MetaKeys.ORIGINAL_AFFINE] = self._get_affine(img, self.affine_lps_to_ras)\n",
    "        header[MetaKeys.SPACE] = SpaceKeys.RAS if self.affine_lps_to_ras else SpaceKeys.LPS\n",
    "        header[MetaKeys.AFFINE] = header[MetaKeys.ORIGINAL_AFFINE].copy()\n",
    "        header[MetaKeys.SPATIAL_SHAPE] = self._get_spatial_shape(img)\n",
    "        # default to \"no_channel\" or -1\n",
    "        header[MetaKeys.ORIGINAL_CHANNEL_DIM] = (float(\"nan\") if len(data.shape) == len(header[MetaKeys.SPATIAL_SHAPE]) else -1)\n",
    "        self._copy_compatible_dict(header, compatible_meta)\n",
    "        return self._stack_images(img_array, compatible_meta), compatible_meta\n",
    "        \n",
    "    def _get_meta_dict(self, img) -> dict:\n",
    "        img_meta_dict = img.GetMetaDataKeys()\n",
    "        meta_dict: dict = {}\n",
    "        for key in img_meta_dict:\n",
    "            if key.startswith(\"ITK_\"):\n",
    "                continue\n",
    "            val = img.GetMetaData(key)\n",
    "            meta_dict[key] = np.asarray(val) if type(val).__name__.startswith(\"itk\") else val\n",
    "        meta_dict[\"spacing\"] = np.asarray(img.GetSpacing())\n",
    "        return dict(meta_dict)\n",
    "\n",
    "    def _get_affine(self, img, lps_to_ras: bool = True):\n",
    "        dir_array = img.GetDirection()\n",
    "        direction = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]])\n",
    "        spacing = np.asarray(img.GetSpacing())\n",
    "        origin = np.asarray(img.GetOrigin())\n",
    "        sr = min(max(direction.shape[0], 1), 3)\n",
    "        affine: np.ndarray = np.eye(sr + 1)\n",
    "        affine[:sr, :sr] = direction[:sr, :sr] @ np.diag(spacing[:sr])\n",
    "        affine[:sr, -1] = origin[:sr]\n",
    "        if lps_to_ras:\n",
    "            affine = orientation_ras_lps(affine)\n",
    "        return affine\n",
    "\n",
    "    def _get_spatial_shape(self, img):\n",
    "        ## Not handling multichannel images with SimpleITK\n",
    "        dir_array = img.GetDirection()\n",
    "        sr = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]]).shape[0]\n",
    "        sr = max(min(sr, 3), 1)\n",
    "        _size = list(img.GetSize())\n",
    "        return np.asarray(_size[:sr])\n",
    "\n",
    "    def _get_array_data(self, img):\n",
    "        ## Not handling multichannel images with SimpleITK\n",
    "        np_img = sitk.GetArrayFromImage(img)\n",
    "        return np_img if self.reverse_indexing else np_img.T\n",
    "    \n",
    "    def _stack_images(self, image_list: list, meta_dict: dict):\n",
    "        if len(image_list) <= 1:\n",
    "            return image_list[0]\n",
    "        if not is_no_channel(meta_dict.get(MetaKeys.ORIGINAL_CHANNEL_DIM, None)):\n",
    "            channel_dim = int(meta_dict[MetaKeys.ORIGINAL_CHANNEL_DIM])\n",
    "            return np.concatenate(image_list, axis=channel_dim)\n",
    "        # stack at a new first dim as the channel dim, if `'original_channel_dim'` is unspecified\n",
    "        meta_dict[MetaKeys.ORIGINAL_CHANNEL_DIM] = 0\n",
    "        return np.stack(image_list, axis=0)\n",
    "\n",
    "    def _copy_compatible_dict(self, from_dict: dict, to_dict: dict):\n",
    "        if not isinstance(to_dict, dict):\n",
    "            raise ValueError(f\"to_dict must be a Dict, got {type(to_dict)}.\")\n",
    "        if not to_dict:\n",
    "            for key in from_dict:\n",
    "                datum = from_dict[key]\n",
    "                if isinstance(datum, np.ndarray) and np_str_obj_array_pattern.search(datum.dtype.str) is not None:\n",
    "                    continue\n",
    "                to_dict[key] = str(TraceKeys.NONE) if datum is None else datum  # NoneType to string for default_collate\n",
    "        else:\n",
    "            affine_key, shape_key = MetaKeys.AFFINE, MetaKeys.SPATIAL_SHAPE\n",
    "            if affine_key in from_dict and not np.allclose(from_dict[affine_key], to_dict[affine_key]):\n",
    "                raise RuntimeError(\n",
    "                    \"affine matrix of all images should be the same for channel-wise concatenation. \"\n",
    "                    f\"Got {from_dict[affine_key]} and {to_dict[affine_key]}.\"\n",
    "                )\n",
    "            if shape_key in from_dict and not np.allclose(from_dict[shape_key], to_dict[shape_key]):\n",
    "                raise RuntimeError(\n",
    "                    \"spatial_shape of all images should be the same for channel-wise concatenation. \"\n",
    "                    f\"Got {from_dict[shape_key]} and {to_dict[shape_key]}.\"\n",
    "            )\n",
    "                \n",
    "class LoadSitkImage(Transform):\n",
    "    def __init__(self,\n",
    "            image_only: bool = False,\n",
    "            dtype: DtypeLike or None = np.float32,\n",
    "            ensure_channel_first: bool = False,\n",
    "            simple_keys: bool = False,\n",
    "            prune_meta_pattern: str or None = None,\n",
    "            prune_meta_sep: str = \".\",   \n",
    "        ) -> None:\n",
    "        self.reader = sitkReader()\n",
    "        self.image_only = image_only\n",
    "        self.ensure_channel_first = ensure_channel_first\n",
    "        self.dtype = dtype\n",
    "        self.simple_keys = simple_keys\n",
    "        self.pattern = prune_meta_pattern\n",
    "        self.sep = prune_meta_sep\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, sitk.SimpleITK.Image):\n",
    "            raise RuntimeError(f\"{self.__class__.__name__} The input image is not an ITK object.\\n\")    \n",
    "        img_array, meta_data = self.reader.get_data(img)\n",
    "        img_array = convert_to_dst_type(img_array, dst=img_array, dtype=self.dtype)[0]\n",
    "        if not isinstance(meta_data, dict):\n",
    "            raise ValueError(f\"`meta_data` must be a dict, got type {type(meta_data)}.\")\n",
    "        # Here I changed from original LoadImage to use tensor instead of numpy array (img_array) \n",
    "        # so the result is similar to loading the nifti file with LoadImage\n",
    "        img = MetaTensor.ensure_torch_and_prune_meta(\n",
    "            torch.from_numpy(img_array), meta_data, self.simple_keys, pattern=self.pattern, sep=self.sep\n",
    "        )\n",
    "        if self.ensure_channel_first:\n",
    "            img = EnsureChannelFirst()(img)\n",
    "        if self.image_only:\n",
    "            return img\n",
    "        return img, img.meta if isinstance(img, MetaTensor) else meta_data\n",
    "\n",
    "\n",
    "import itk \n",
    "class LoadITKImage(Transform):\n",
    "    def __init__(self,\n",
    "            image_only: bool = False,\n",
    "            dtype: DtypeLike or None = np.float32,\n",
    "            ensure_channel_first: bool = False,\n",
    "            simple_keys: bool = False,\n",
    "            prune_meta_pattern: str or None = None,\n",
    "            prune_meta_sep: str = \".\",   \n",
    "        ) -> None:\n",
    "        self.reader = ITKReader()\n",
    "        self.image_only = image_only\n",
    "        self.ensure_channel_first = ensure_channel_first\n",
    "        self.dtype = dtype\n",
    "        self.simple_keys = simple_keys\n",
    "        self.pattern = prune_meta_pattern\n",
    "        self.sep = prune_meta_sep\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, itk.itkImagePython.itkImageF3):\n",
    "            raise RuntimeError(f\"{self.__class__.__name__} The input image is not an ITK object.\\n\")\n",
    "        img_array, meta_data = self.reader.get_data(img)\n",
    "        img_array = convert_to_dst_type(img_array, dst=img_array, dtype=self.dtype)[0]\n",
    "        if not isinstance(meta_data, dict):\n",
    "            raise ValueError(f\"`meta_data` must be a dict, got type {type(meta_data)}.\")\n",
    "        # Here I changed from original LoadImage to use tensor instead of numpy array (img_array) \n",
    "        # so the result is similar to loading the nifti file with LoadImage\n",
    "        img = MetaTensor.ensure_torch_and_prune_meta(\n",
    "            torch.from_numpy(img_array), meta_data, self.simple_keys, pattern=self.pattern, sep=self.sep\n",
    "        )\n",
    "        if self.ensure_channel_first:\n",
    "            img = EnsureChannelFirst()(img)\n",
    "        if self.image_only:\n",
    "            return img\n",
    "        return img, img.meta if isinstance(img, MetaTensor) else meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadSitkImaged(MapTransform):\n",
    "    def __init__(self,\n",
    "            keys: KeysCollection,\n",
    "            dtype: DtypeLike = np.float32,\n",
    "            meta_keys: KeysCollection or None=None,\n",
    "            meta_key_postfix: str=DEFAULT_POST_FIX,\n",
    "            overwriting: bool=False,\n",
    "            image_only: bool=False,\n",
    "            ensure_channel_first: bool=False,\n",
    "            simple_keys: bool=False,\n",
    "            prune_meta_pattern: str or None=None,\n",
    "            prune_meta_sep: str=\".\",\n",
    "            allow_missing_keys: bool=False,\n",
    "        ):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self._loader = LoadSitkImage(\n",
    "            image_only,\n",
    "            dtype,\n",
    "            ensure_channel_first,\n",
    "            simple_keys,\n",
    "            prune_meta_pattern,\n",
    "            prune_meta_sep\n",
    "        ) \n",
    "        if not isinstance(meta_key_postfix, str):\n",
    "            raise TypeError(f\"meta_key_postfix must be a str but is {type(meta_key_postfix).__name__}.\")\n",
    "        self.meta_keys = ensure_tuple_rep(None, len(self.keys)) if meta_keys is None else ensure_tuple(meta_keys)\n",
    "        if len(self.keys) != len(self.meta_keys):\n",
    "            raise ValueError(\n",
    "                f\"meta_keys should have the same length as keys, got {len(self.keys)} and {len(self.meta_keys)}.\"\n",
    "            )\n",
    "        self.meta_key_postfix = ensure_tuple_rep(meta_key_postfix, len(self.keys))\n",
    "        self.overwriting = overwriting\n",
    "        \n",
    "        \n",
    "    def __call__(self, img):\n",
    "        d = dict(img)\n",
    "        for key, meta_key, meta_key_postfix in self.key_iterator(d, self.meta_keys, self.meta_key_postfix):\n",
    "            img = self._loader(d[key])\n",
    "            if self._loader.image_only:\n",
    "                d[key] = img\n",
    "            else:\n",
    "                if not isinstance(img, (tuple, list)):\n",
    "                    raise ValueError(\n",
    "                        f\"loader must return a tuple or list (because image_only=False was used), got {type(data)}.\"\n",
    "                    )\n",
    "                d[key] = img[0]\n",
    "                if not isinstance(img[1], dict):\n",
    "                    raise ValueError(f\"metadata must be a dict, got {type(img[1])}.\")\n",
    "                meta_key = meta_key or f\"{key}_{meta_key_postfix}\"\n",
    "                if meta_key in d and not self.overwriting:\n",
    "                    raise KeyError(f\"Metadata with key {meta_key} already exists and overwriting=False.\")\n",
    "                d[meta_key] = img[1]\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "itk_img = itk.imread(train_files[0]['image_1']).astype(itk.F)\n",
    "sitk_img = sitk.ReadImage(train_files[0]['image_1'], sitk.sitkFloat32)\n",
    "\n",
    "# print(sitk_img.GetSpacing())\n",
    "# print(itk.affine_lps_to_ras(itk_img))\n",
    "\n",
    "itk_img.GetNumberOfComponentsPerPixel\n",
    "\n",
    "\n",
    "dir_array = sitk_img.GetDirection()\n",
    "sr = np.array([dir_array[0:3],dir_array[3:6],dir_array[6:9]]).shape[0]\n",
    "sr = max(min(sr, 3), 1)\n",
    "_size = list(sitk_img.GetSize())\n",
    "print(np.asarray(_size[:sr]))\n",
    "\n",
    "\n",
    "\n",
    "sr = itk.array_from_matrix(itk_img.GetDirection()).shape[0]\n",
    "sr = max(min(sr, 3), 1)\n",
    "_size = list(itk.size(itk_img))\n",
    "print(np.asarray(_size[:sr]))\n",
    "    \n",
    "    \n",
    "# print(itk.array_from_matrix(itk_img.GetDirection()))\n",
    "# itk.array_from_matrix(img.GetDirection()).shape[0]\n",
    "\n",
    "print(np.asarray(sitk_img.GetSize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ImageLoad\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n",
    "\n",
    "# Make list with two images filenames\n",
    "data_list = [train_files[0]['image_1'], train_files[0]['image_2']]\n",
    "\n",
    "load_file = Compose([LoadImage(image_only=False)])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "# print((output_original[0][1])) # See metatensor for first output\n",
    "# print((output_original[0][1])) # See dictionary for first output\n",
    "metatensor_1 = output_original[0][0]\n",
    "metatensor_2 = output_original[1][0]\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n",
    "\n",
    "# LOAD WITH ITK IMAGE LOADER TO COMPARE\n",
    "itk_image_1 = itk.imread(train_files[0]['image_1']).astype(itk.F)\n",
    "itk_image_2 = itk.imread(train_files[0]['image_2']).astype(itk.F)\n",
    "\n",
    "# Make list with two itk image objects\n",
    "data_list = [itk_image_1, itk_image_2]\n",
    "\n",
    "load_itk = Compose([LoadITKImage()])\n",
    "output_original = load_itk(data_list)\n",
    "metatensor_1 = output_original[0][0]\n",
    "metatensor_2 = output_original[1][0]\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n",
    "\n",
    "# TEST NEW CUSTOM SITK LOADER\n",
    "sitk_image_1 = sitk.ReadImage(train_files[0]['image_1'], sitk.sitkFloat32)\n",
    "sitk_image_2 = sitk.ReadImage(train_files[0]['image_2'], sitk.sitkFloat32)\n",
    "\n",
    "# Make list with two sitk image objectss\n",
    "data_list = [sitk_image_1, sitk_image_2]\n",
    "\n",
    "load_sitk = Compose([LoadSitkImage()])\n",
    "output_original = load_sitk(data_list)\n",
    "metatensor_1 = output_original[0][0]\n",
    "metatensor_2 = output_original[1][0]\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ImageLoadd\n",
    "data_list = generateLabeledFileList(param, 'test')\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "\n",
    "load_file = Compose([LoadImaged(keys=['image_1', 'image_2'], image_only=False)])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "\n",
    "metatensor_1 = output_original[0]['image_1']\n",
    "metatensor_2 = output_original[1]['image_1']\n",
    "\n",
    "print('Image_1 - Mag')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n",
    "\n",
    "metatensor_1 = output_original[0]['image_2']\n",
    "metatensor_2 = output_original[1]['image_2']\n",
    "\n",
    "print('Image_2 - Phase')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sitkLoadD\n",
    "prefix = 'test'\n",
    "images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "\n",
    "data_list = []\n",
    "for image_m_name, image_p_name in zip(images_m, images_p):\n",
    "    sitk_image_1 = sitk.ReadImage(image_m_name, sitk.sitkFloat32)\n",
    "    sitk_image_2 = sitk.ReadImage(image_p_name, sitk.sitkFloat32)\n",
    "    data_list.append({\"image_1\": sitk_image_1, \"image_2\": sitk_image_2,})\n",
    "\n",
    "\n",
    "# LOAD WITH STANDARD IMAGE LOADER\n",
    "\n",
    "load_file = Compose([LoadSitkImaged(keys=['image_1', 'image_2'], image_only=False)])\n",
    "output_original = load_file(data_list) # Output is a list of tuples. Each tuple, with a pair of metatensor and dict\n",
    "\n",
    "metatensor_1 = output_original[0]['image_1']\n",
    "metatensor_2 = output_original[1]['image_1']\n",
    "\n",
    "print('Image_1 - Mag')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])\n",
    "\n",
    "metatensor_1 = output_original[0]['image_2']\n",
    "metatensor_2 = output_original[1]['image_2']\n",
    "\n",
    "print('Image_2 - Phase')\n",
    "print(metatensor_1.data.shape)\n",
    "print(metatensor_1.data[0,0])\n",
    "print(metatensor_2.data[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_transform = Compose([LoadSitkImaged(keys=[\"image_1\", \"image_2\"]), EnsureChannelFirstd(keys=[\"image_1\", \"image_2\"])])\n",
    "output_original = inference_transform(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transforms\n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\")\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "    ]\n",
    "    \n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))\n",
    "    transform_array.append(ScaleIntensityd(keys=[\"image\", \"label\"], minv=0, maxv=1, channel_wise=True))\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\")))\n",
    "\n",
    "# Plot original\n",
    "loadTest = Compose(transform_array)\n",
    "output_original = loadTest(train_files)\n",
    "\n",
    "for i in range(len(output_original)):\n",
    "    if len(output_original)==1:\n",
    "        output_dict = output_original[0]\n",
    "    else:\n",
    "        output_dict = output_original[0][i]\n",
    "    # output_dict = output[0]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    # image = output_dict[0]['image']\n",
    "    # label = output_dict[0]['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 Original')\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 Original')\n",
    "    show_array(label_array[0,:,:,:], title='Label Original')\n",
    "\n",
    "# Data augmentation\n",
    "transform_array.append(RandZoomd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.1,\n",
    "    min_zoom=1.0,\n",
    "    max_zoom=1.3,\n",
    "    mode=['area', 'nearest'],\n",
    "))\n",
    "transform_array.append(RandFlipd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.5,\n",
    "    spatial_axis=2,\n",
    "))\n",
    "# Balance background/foreground\n",
    "transform_array.append(RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=param.window_size,\n",
    "    pos=5, \n",
    "    neg=1,\n",
    "    num_samples=5,\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0, \n",
    "))\n",
    "\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "N = len(output[0])\n",
    "for i in range(N):\n",
    "    output_dict = output[0][i]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 '+ str(i+1))\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 '+ str(i+1))\n",
    "    show_array(label_array[0,:,:,:], title='Label '+ str(i+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import UNet\n",
    "\n",
    "# # Define the UNet architecture\n",
    "# model_unet = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=[16, 32, 64, 128],\n",
    "#     strides=[(1, 2, 2), (1, 2, 2), (1, 1, 1)],\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "\n",
    "# # Create an example input tensor\n",
    "# input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# # Pass the input tensor through the UNet model\n",
    "# output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# # Print the size of the output tensor\n",
    "# print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
