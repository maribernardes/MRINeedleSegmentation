{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, ensure_tuple\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandGaussianNoised,\n",
    "    RandRicianNoised,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    ")\n",
    "\n",
    "from sitkIO import PushSitkImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.label_type = label_type\n",
    "        self.training_rand_noise = rand_noise\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_\"+param.label_type+\"_label.nii.gz\")))\n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dictionary\n",
      "Reading labeled images from: /Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook\n",
      "Use magnitude/phase images\n",
      "[{'image_1': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz', 'image_2': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz', 'label': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_labels/SyntheticImage_001_multi_label.nii.gz'}, {'image_1': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_002_M.nii.gz', 'image_2': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_002_P.nii.gz', 'label': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_labels/SyntheticImage_002_multi_label.nii.gz'}]\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()+''\n",
    "pixel_dim = (1.171875, 1.171875, 3.6)\n",
    "window_size = (48, 48, 3)\n",
    "orientation = 'LIP'\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "input_type = 'MP'\n",
    "label_type = 'multi'\n",
    "rand_noise = 1\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "print(train_files)\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original\n",
    "print('ORIGINAL')\n",
    "\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    load_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), \n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    load_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "loadTest = Compose(load_array)\n",
    "original = loadTest(train_files)\n",
    "N = len(original)\n",
    "for i in range(N):\n",
    "    original_dict = original[i]\n",
    "    image_m = original_dict['image'][0] #ch1\n",
    "    label = original_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "    \n",
    "    if param.in_channels==2:\n",
    "        image_p = original_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTENSITY ADJUST\n",
      "Input shape:  (192, 192, 3)\n",
      "Label shape:  (192, 192, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9b9709410e4600ad51a57908f5699c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b95a7ba7b49d2a701a5eae53043c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (192, 192, 3)\n",
      "Label shape:  (192, 192, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce26258573434089ae2c9bcc4580f455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99b512a064e42a49abb440d4f3b4a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define preprocessing transforms\n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), \n",
    "        ScaleIntensityd(keys=[\"image_1\", \"image_2\"], minv=0, maxv=1, channel_wise=True)\n",
    "    ]\n",
    "    if param.training_rand_noise == 1:\n",
    "        transform_array.append(RandRicianNoised(keys=[\"image_1\"], prob=1, mean=0, std=0.1))\n",
    "        transform_array.append(RandGaussianNoised(keys=[\"image_2\"], prob=1, mean=0, std=0.08))\n",
    "    transform_array.append(ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"))\n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True)\n",
    "    ]\n",
    "    if param.training_rand_noise == 1:\n",
    "        transform_array.append(RandGaussianNoised(keys=[\"image\"], prob=1, mean=0, std=0.1))\n",
    "    \n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))\n",
    " \n",
    "# Think this should be removed (was extra by accident)   \n",
    "# transform_array.append(ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True))\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\")))\n",
    "\n",
    "# Intensity adjustment and noise addition\n",
    "print('INTENSITY ADJUST')\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "intensityTest = Compose(transform_array)\n",
    "output = intensityTest(train_files)\n",
    "N = len(output)\n",
    "for i in range(N):\n",
    "    output_dict = output[i]\n",
    "    image_m = output_dict['image'][0] #ch1\n",
    "    label = output_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "\n",
    "    if param.in_channels==2:\n",
    "        image_p = output_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== DATA AUGMENTATION ==\n",
      "Input shape:  (48, 48, 3)\n",
      "Label shape:  (48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ec4673136948ca89d80d5b9f82aad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90017d0c7b4ee5871fb95a570de730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (48, 48, 3)\n",
      "Label shape:  (48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390b91ca7a0c42a1bcab7a855819d283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5696c8f661400ca3aac345e4fe6358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (48, 48, 3)\n",
      "Label shape:  (48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a629b4efa3f94e1fbba91d7ad4fe5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a9418c0c7458ba14db2a084c87c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (48, 48, 3)\n",
      "Label shape:  (48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d9e1db0d4143f9b9402284fc47d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d38730f660e4e3b85914b80be085e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (48, 48, 3)\n",
      "Label shape:  (48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a768113da1a94e8d9930d79097cd9455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610756b501e84ff6ae0ddcfe2e7be569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data augmentation\n",
    "transform_array.append(RandZoomd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.1,\n",
    "    min_zoom=1.0,\n",
    "    max_zoom=1.3,\n",
    "    mode=['area', 'nearest'],\n",
    "))\n",
    "transform_array.append(RandFlipd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.5,\n",
    "    spatial_axis=2,\n",
    "))\n",
    "# Balance background/foreground\n",
    "transform_array.append(RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=param.window_size,\n",
    "    pos=5, \n",
    "    neg=1,\n",
    "    num_samples=5,\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0, \n",
    "))\n",
    "\n",
    "print('== DATA AUGMENTATION ==')\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "N = len(output[0])\n",
    "for i in range(N):\n",
    "    output_dict = output[0][i]\n",
    "    image_m = output_dict['image'][0] #ch1\n",
    "    label = output_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "\n",
    "    if param.in_channels==2:\n",
    "        image_p = output_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import UNet\n",
    "\n",
    "# # Define the UNet architecture\n",
    "# model_unet = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=[16, 32, 64, 128],\n",
    "#     strides=[(1, 2, 2), (1, 2, 2), (1, 1, 1)],\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "\n",
    "# # Create an example input tensor\n",
    "# input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# # Pass the input tensor through the UNet model\n",
    "# output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# # Print the size of the output tensor\n",
    "# print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
