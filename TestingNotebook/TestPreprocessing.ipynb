{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, ensure_tuple\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandGaussianNoised,\n",
    "    RandRicianNoised,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    "    RandKSpaceSpikeNoised,\n",
    "    KSpaceSpikeNoised\n",
    ")\n",
    "\n",
    "from sitkIO import PushSitkImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise, spike_noise, rand_flip, rand_zoom):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.label_type = label_type\n",
    "        self.training_rand_noise = rand_noise\n",
    "        self.training_spike_noise = spike_noise\n",
    "        self.training_rand_flip = rand_flip\n",
    "        self.training_rand_zoom = rand_zoom\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_\"+param.label_type+\"_label.nii.gz\")))\n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dictionary\n",
      "Reading labeled images from: /Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook\n",
      "Use magnitude/phase images\n",
      "[{'image_1': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz', 'image_2': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz', 'label': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_labels/SyntheticImage_001_multi_label.nii.gz'}, {'image_1': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_002_M.nii.gz', 'image_2': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_002_P.nii.gz', 'label': '/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_labels/SyntheticImage_002_multi_label.nii.gz'}]\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()+''\n",
    "pixel_dim = (3.6, 1.171875, 1.171875)\n",
    "window_size = (3, 64, 64)\n",
    "orientation = 'PIL'\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "input_type = 'MP'\n",
    "label_type = 'multi'\n",
    "rand_noise = 0.8\n",
    "spike_noise = 0.0\n",
    "rand_flip = 0.5\n",
    "rand_zoom = 0.5\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise, spike_noise, rand_flip, rand_zoom)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "print(train_files)\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL\n",
      "Input shape:  (3, 192, 192)\n",
      "Label shape:  (3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f411e2955c4d4badaf1a496c096267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a495b1ddaac84c3ea122a4a76f51b08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (3, 192, 192)\n",
      "Label shape:  (3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3c38eac9f2418d83d6a9beefd55ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92138233eeda4ea7b29424ad1b67e57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original\n",
    "print('ORIGINAL')\n",
    "\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    load_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), \n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    load_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "loadTest = Compose(load_array)\n",
    "original = loadTest(train_files)\n",
    "N = len(original)\n",
    "for i in range(N):\n",
    "    original_dict = original[i]\n",
    "    image_m = original_dict['image'][0] #ch1\n",
    "    label = original_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "    \n",
    "    if param.in_channels==2:\n",
    "        image_p = original_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "ADD NOISE\n",
      "INTENSITY ADJUST\n",
      "Input shape:  (3, 192, 192)\n",
      "Label shape:  (3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c53859210eb4813a7ae12e5496d94da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1623696fc26e4f5f960b9df8c58967e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define preprocessing transforms    \n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),             # Load Magnitude, Phase and labelmap\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]),                      # Ensure channel first\n",
    "        ScaleIntensityd(keys=[\"image_1\", \"image_2\"], minv=0, maxv=1, channel_wise=True) # Scale intensity to 0-1\n",
    "    ]\n",
    "    # Noise addition\n",
    "    print(param.training_rand_noise)\n",
    "    if param.training_rand_noise != 0:\n",
    "        if random.random() < param.training_rand_noise: # Probability of adding noise\n",
    "            print('ADD NOISE')\n",
    "            transform_array.append(RandRicianNoised(keys=[\"image_1\"], prob=1, mean=0, std=0.1))     # Add Rician noise to Magnitude -  mean=0, std=0.1\n",
    "            transform_array.append(RandGaussianNoised(keys=[\"image_2\"], prob=1, mean=0, std=0.08))  # Add small Gaussian noise to Phase - mean=0, std=0.08\n",
    "    transform_array.append(ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"))     # Concatenate Magnitude and Phase to 2-channels       \n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),                          # Load Magnitude and labelmap\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),         # Ensure channel first\n",
    "        ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True)              # Scale intensity to 0-1\n",
    "    ]\n",
    "    # Noise addition\n",
    "    if param.training_rand_noise != 0:\n",
    "        transform_array.append(RandRicianNoised(keys=[\"image\"], prob=param.training_rand_noise, mean=0, std=0.1))           # Add Rician noise to Magnitude \n",
    "\n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))                  # Increase contrast for real/imaginary\n",
    "ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True) # Re-scale intensity after noise addition\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))                            # Adjust image orientation\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\"))) # Adjust image spacing\n",
    "\n",
    "# Spike noise addition\n",
    "if param.training_spike_noise != 0:\n",
    "    transform_array.append(RandKSpaceSpikeNoised(keys=['image'], prob=param.training_spike_noise, channel_wise=False, intensity_range=(0.95*8.6,1.10*8.6)))\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True) # Re-scale intensity after noise addition\n",
    "        \n",
    "# Intensity adjustment and noise addition\n",
    "print('INTENSITY ADJUST')\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "intensityTest = Compose(transform_array)\n",
    "output = intensityTest(train_files)\n",
    "N = len(output)\n",
    "N=1\n",
    "for i in range(N):\n",
    "    output_dict = output[i]\n",
    "    image_m = output_dict['image'][0] #ch1\n",
    "    label = output_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "\n",
    "    if param.in_channels==2:\n",
    "        image_p = output_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (3, 192, 192)\n",
      "Label shape:  (3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d482baa9af6847669e26a8c761c46619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f61e9cccf1449b80943ba9f4b1cfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=95, description='z', max=191), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform_array.append(RandKSpaceSpikeNoised(\n",
    "    keys=['image'],\n",
    "    prob=1.0,\n",
    "    channel_wise=False,\n",
    "    intensity_range=(6.5,6.5),\n",
    "))\n",
    "\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "N = len(output)\n",
    "N=1\n",
    "for i in range(N):\n",
    "    output_dict = output[i]\n",
    "    image_m = output_dict['image'][0] #ch1\n",
    "    label = output_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "\n",
    "    if param.in_channels==2:\n",
    "        image_p = output_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== DATA AUGMENTATION ==\n",
      "Input shape:  (3, 64, 64)\n",
      "Label shape:  (3, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Num foregrounds 0, Num backgrounds 110592, unable to generate class balanced samples, setting `pos_ratio` to 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93b8721db4941fa952c6d495e3719f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='z', max=63), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba43e8efaa840cdbfbd0038aed0f8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='z', max=63), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Data augmentation\n",
    "transform_array.append(RandZoomd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=param.training_rand_zoom,\n",
    "    min_zoom=1.0,\n",
    "    max_zoom=1.3,\n",
    "    mode=['area', 'nearest'],\n",
    "))\n",
    "\n",
    "transform_array.append(RandFlipd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=param.training_rand_flip,\n",
    "    spatial_axis=2,\n",
    "))\n",
    "\n",
    "# Balance background/foreground\n",
    "transform_array.append(RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=param.window_size,\n",
    "    pos=5, \n",
    "    neg=1,\n",
    "    num_samples=3,\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0, \n",
    "))\n",
    "\n",
    "print('== DATA AUGMENTATION ==')\n",
    "sitkTransform = PushSitkImage(resample=False, output_dtype=np.float32, print_log=False)\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "N = len(output[0])\n",
    "N=1\n",
    "for i in range(N):\n",
    "    output_dict = output[0][i]\n",
    "    image_m = output_dict['image'][0] #ch1\n",
    "    label = output_dict['label'][0]   #ch1\n",
    "    sitk_image_m = sitkTransform(image_m)\n",
    "    sitk_label = sitkTransform(label)\n",
    "    print('Input shape: ', sitk_image_m.GetSize())\n",
    "    print('Label shape: ', sitk_label.GetSize())\n",
    "\n",
    "    if param.in_channels==2:\n",
    "        image_p = output_dict['image'][1] #ch2\n",
    "        sitk_image_p = sitkTransform(image_p)\n",
    "        show_mag_phase_images(sitk_image_m, sitk_image_p, title = 'Input images')\n",
    "    else:\n",
    "        show_image(sitk_image_m, title='Input image')\n",
    "    show_image(sitk_label, title = 'Label')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL\n",
      "torch.Size([1, 2, 3, 192, 192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "if param.axcodes == 'PIL':\n",
    "    print('PIL')\n",
    "    strides = [(1, 2, 2), (1, 2, 2), (1, 1, 1)]   # PIL\n",
    "else:   \n",
    "    print('LIP') \n",
    "    strides = [(2, 2, 1), (2, 2, 1), (1, 1, 1)]   # LIP\n",
    "\n",
    "# Define the UNet architecture\n",
    "model_unet = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=[16, 32, 64, 128],\n",
    "    strides=strides,\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "# Create an example input tensor\n",
    "input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# Pass the input tensor through the UNet model\n",
    "output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# Print the size of the output tensor\n",
    "print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
