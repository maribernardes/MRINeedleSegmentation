{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, num_samples):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_both_label.nii.gz\")))\n",
    "    \n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()\n",
    "pixel_dim = (3.6, 1.171875, 1.171875)\n",
    "window_size = (3, 160, 160)\n",
    "orientation = 'PIL'\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "input_type = 'M'\n",
    "num_samples = 2\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, num_samples)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing transforms\n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\")\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'), # Mariana: AddChanneld(keys=[\"image\", \"label\"]) deprecated, use EnsureChannelFirst instead\n",
    "    ]\n",
    "    \n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))\n",
    "transform_array.append(ScaleIntensityd(keys=[\"image\", \"label\"], minv=0, maxv=1, channel_wise=True))\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\")))\n",
    "\n",
    "# Plot original\n",
    "loadTest = Compose(transform_array)\n",
    "output_original = loadTest(train_files)\n",
    "\n",
    "for i in range(len(output_original)):\n",
    "    if len(output_original)==1:\n",
    "        output_dict = output_original[0]\n",
    "    else:\n",
    "        output_dict = output_original[0][i]\n",
    "    # output_dict = output[0]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    # image = output_dict[0]['image']\n",
    "    # label = output_dict[0]['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 Original')\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 Original')\n",
    "    show_array(label_array[0,:,:,:], title='Label Original')\n",
    "\n",
    "# Data augmentation\n",
    "transform_array.append(RandZoomd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.5,\n",
    "    min_zoom=1.1,\n",
    "    max_zoom=1.5,\n",
    "    mode=['area', 'nearest'],\n",
    "))\n",
    "transform_array.append(RandFlipd(\n",
    "    keys=['image', 'label'],\n",
    "    prob=0.5,\n",
    "    spatial_axis=2,\n",
    "))\n",
    "# Balance background/foreground\n",
    "# transform_array.append(RandCropByPosNegLabeld(\n",
    "#     keys=[\"image\", \"label\"],\n",
    "#     label_key=\"label\",\n",
    "#     spatial_size=param.window_size,\n",
    "#     pos=1, #0.8\n",
    "#     neg=1, #0.2\n",
    "#     num_samples=2,\n",
    "#     image_key=\"image\",\n",
    "#     image_threshold=0, #0.05\n",
    "# ))\n",
    "transform_array.append(RandCropByLabelClassesd(\n",
    "    keys=[\"image\", \"label\"], \n",
    "    label_key=\"label\", \n",
    "    spatial_size=param.window_size, \n",
    "    ratios=[1,3], \n",
    "    num_classes=2,\n",
    "    num_samples=param.num_samples, \n",
    "    image_key=\"image\", \n",
    "    image_threshold=0,\n",
    "))\n",
    "\n",
    "\n",
    "transfTest = Compose(transform_array)\n",
    "output = transfTest(train_files)\n",
    "\n",
    "for i in range(param.num_samples):\n",
    "    # if len(output)==1:\n",
    "    #     output_dict = output[0]\n",
    "    # else:\n",
    "    output_dict = output[0][i]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    show_array(image_array[0,:,:,:], title='Ch1 '+ str(i))\n",
    "    if image_array.shape[0]==2:\n",
    "        show_array(image_array[1,:,:,:], title='Ch2 '+ str(i))\n",
    "    show_array(label_array[0,:,:,:], title='Label '+ str(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import UNet\n",
    "\n",
    "# # Define the UNet architecture\n",
    "# model_unet = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=[16, 32, 64, 128],\n",
    "#     strides=[(1, 2, 2), (1, 2, 2), (1, 1, 1)],\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "\n",
    "# # Create an example input tensor\n",
    "# input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# # Pass the input tensor through the UNet model\n",
    "# output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# # Print the size of the output tensor\n",
    "# print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
