{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for testing MONAI transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "path = os.path.dirname(current_directory)\n",
    "sys.path.append(path)\n",
    "from Utils import *\n",
    "\n",
    "%matplotlib widget\n",
    "from ipywidgets import interact, interactive, widgets\n",
    "from matplotlib.patches import Rectangle, Circle, Arrow\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Mapping, Hashable\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.utils import first, ensure_tuple\n",
    "from monai.config import KeysCollection\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.transforms import (\n",
    "    AdjustContrastd,\n",
    "    Transform,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    Orientation,\n",
    "    ConcatItemsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureChannelFirst,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    CropForegroundd,\n",
    "    RandGaussianNoised,\n",
    "    RandRicianNoised,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise):\n",
    "        self.data_dir = data_dir\n",
    "        self.pixel_dim = pixel_dim\n",
    "        self.window_size = window_size\n",
    "        self.axcodes = orientation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_type = input_type\n",
    "        self.label_type = label_type\n",
    "        self.training_rand_noise = rand_noise\n",
    "\n",
    "def generateLabeledFileList(param, prefix):\n",
    "    print('Reading labeled images from: ' + param.data_dir)\n",
    "    images_m = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_M.nii.gz\")))\n",
    "    images_p = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_P.nii.gz\")))\n",
    "    images_r = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_R.nii.gz\")))\n",
    "    images_i = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_images\", \"*_I.nii.gz\")))\n",
    "    labels = sorted(glob.glob(os.path.join(param.data_dir, prefix + \"_labels\", \"*_\"+param.label_type+\"_label.nii.gz\")))\n",
    "    # Use two types of images combined\n",
    "    if param.in_channels==2:\n",
    "        # Use real and imaginary images\n",
    "        if param.input_type=='R' or param.input_type=='I':\n",
    "            print('Use real/imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_r_name, \"image_2\": image_i_name, \"label\":label_name}\n",
    "                for image_r_name, image_i_name, label_name in zip(images_r, images_i, labels)\n",
    "            ]\n",
    "        # Use magnitude and phase images\n",
    "        else:\n",
    "            print('Use magnitude/phase images')\n",
    "            data_dicts = [\n",
    "                {\"image_1\": image_m_name, \"image_2\": image_p_name, \"label\":label_name}\n",
    "                for image_m_name, image_p_name, label_name in zip(images_m, images_p, labels)\n",
    "            ]\n",
    "    # Use only one type of image        \n",
    "    else:\n",
    "        # Use real images\n",
    "        if param.input_type=='R':\n",
    "            print('Use real images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_r, labels)\n",
    "            ]\n",
    "        # Use imaginary images\n",
    "        elif param.input_type=='I':\n",
    "            print('Use imaginary images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_i, labels)\n",
    "            ]\n",
    "        # Use phase images\n",
    "        elif param.input_type=='P':\n",
    "            print('Use phase images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_p, labels)\n",
    "            ]\n",
    "        # Use magnitude images\n",
    "        else:\n",
    "            print('Use magnitude images')\n",
    "            data_dicts = [\n",
    "                {\"image\": image_name, \"label\": label_name}\n",
    "                for image_name, label_name in zip(images_m, labels)\n",
    "            ]\n",
    "    return data_dicts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dictionary\n",
      "Reading labeled images from: /Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook\n",
      "Use magnitude/phase images\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_M.nii.gz\n",
      "/Users/pl771/Devel/MRINeedleSegmentation-LIVER/TestingNotebook/test_images/SyntheticImage_001_P.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Build param (info from config.ini)\n",
    "data_dir = os.getcwd()\n",
    "pixel_dim = (3.6, 1.171875, 1.171875)\n",
    "window_size = (3, 48, 48)\n",
    "orientation = 'PIL'\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "input_type = 'MP'\n",
    "label_type = 'multi'\n",
    "rand_noise = 1\n",
    "param = Param(data_dir, pixel_dim, window_size, orientation, in_channels, out_channels, input_type, label_type, rand_noise)\n",
    "\n",
    "# Create dictionary\n",
    "print('Create dictionary')\n",
    "train_files = generateLabeledFileList(param, 'test')\n",
    "print(train_files[0]['image_1'])\n",
    "print(train_files[0]['image_2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL\n",
      "Image shape: (2, 3, 192, 192)\n",
      "Label shape: (1, 3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b667ef7e064d28940a2f7ddceb6062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c8fb5fac9d4c48a484a36abe98856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86679547d2845bf8a5f5d193a0fc553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original\n",
    "print('ORIGINAL')\n",
    "\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    load_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), \n",
    "        ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "else:\n",
    "    # One channel input\n",
    "    load_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes)\n",
    "    ]\n",
    "\n",
    "loadTest = Compose(load_array)\n",
    "original = loadTest(train_files)\n",
    "N = len(original)\n",
    "N = 1\n",
    "for i in range(N):\n",
    "    original_dict = original[i]\n",
    "    image = original_dict['image']\n",
    "    label = original_dict['label']\n",
    "    # image = output_dict[0]['image']\n",
    "    # label = output_dict[0]['label']\n",
    "    original_image_array = np.array(image)\n",
    "    original_label_array = np.array(label)\n",
    "    print('Image shape: '+ str(original_image_array.shape))\n",
    "    print('Label shape: '+ str(original_label_array.shape))\n",
    "    show_array(original_image_array[0,:,:,:], title='Ch1 Intensity/Noise')\n",
    "    if original_image_array.shape[0]==2:\n",
    "        show_array(original_image_array[1,:,:,:], title='Ch2 Intensity/Noise')\n",
    "    show_array(original_label_array[0,:,:,:], title='Label Intensity/Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTENSITY ADJUST\n",
      "Image shape: (2, 3, 192, 192)\n",
      "Label shape: (1, 3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b480b1709a74a5bad3e79cce61b0d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161665a495c549618f26702112d3bcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d0269b6af34ae8b786347668fe6dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (2, 3, 192, 192)\n",
      "Label shape: (1, 3, 192, 192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13157686d93c49daa4429e1d7b79535c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0cf80d53cd4cf28214d07b5fd5e115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ac01e3ca2c4235bca93632d5ebeb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='z', max=2), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define preprocessing transforms\n",
    "# Load images\n",
    "if param.in_channels==2:\n",
    "    # Two channels input\n",
    "    transform_array = [\n",
    "        LoadImaged(keys=[\"image_1\", \"image_2\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image_1\", \"image_2\", \"label\"]), \n",
    "        ScaleIntensityd(keys=[\"image_1\", \"image_2\"], minv=0, maxv=1, channel_wise=True)\n",
    "    ]\n",
    "    if param.training_rand_noise == 1:\n",
    "        # transform_array.append(RandGaussianNoised(keys=[\"image_1\"], prob=1, mean=0, std=0.1))\n",
    "        transform_array.append(RandRicianNoised(keys=[\"image_1\"], prob=1, mean=0, std=0.1))\n",
    "        transform_array.append(RandGaussianNoised(keys=[\"image_2\"], prob=1, mean=0, std=0.08))\n",
    "    transform_array.append(ConcatItemsd(keys=[\"image_1\", \"image_2\"], name=\"image\"))\n",
    "else:\n",
    "    # One channel input\n",
    "    transform_array = [            \n",
    "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "        ScaleIntensityd(keys=[\"image\"], minv=0, maxv=1, channel_wise=True)\n",
    "    ]\n",
    "    if param.training_rand_noise == 1:\n",
    "        transform_array.append(RandGaussianNoised(keys=[\"image\"], prob=1, mean=0, std=0.1))\n",
    "    \n",
    "# Intensity adjustment\n",
    "if (param.input_type == 'R') or (param.input_type == 'I'):\n",
    "    transform_array.append(AdjustContrastd(keys=[\"image\"], gamma=2.5))\n",
    "    \n",
    "transform_array.append(ScaleIntensityd(keys=[\"image\", \"label\"], minv=0, maxv=1, channel_wise=True))\n",
    "\n",
    "# Spatial adjustments\n",
    "transform_array.append(Orientationd(keys=[\"image\", \"label\"], axcodes=param.axcodes))\n",
    "transform_array.append(Spacingd(keys=[\"image\", \"label\"], pixdim=param.pixel_dim, mode=(\"bilinear\", \"nearest\")))\n",
    "\n",
    "\n",
    "# Intensity adjustment and noise addition\n",
    "print('INTENSITY ADJUST')\n",
    "intensityTest = Compose(transform_array)\n",
    "output = intensityTest(train_files)\n",
    "N = len(output)\n",
    "for i in range(N):\n",
    "    output_dict = output[i]\n",
    "    image = output_dict['image']\n",
    "    label = output_dict['label']\n",
    "    # image = output_dict[0]['image']\n",
    "    # label = output_dict[0]['label']\n",
    "    image_array = np.array(image)\n",
    "    label_array = np.array(label)\n",
    "    print('Image shape: '+ str(image_array.shape))\n",
    "    print('Label shape: '+ str(label_array.shape))\n",
    "    # show_array(image_array[0,:,:,:], title='Ch1 Intensity/Noise')\n",
    "    show_mag_phase_arrays(original_image_array[0,:,:,:],image_array[0,:,:,:], subtitles=['Original Ch1', 'Intensity/Noise Ch1'])\n",
    "    if image_array.shape[0]==2:\n",
    "        show_mag_phase_arrays(original_image_array[1,:,:,:],image_array[1,:,:,:], subtitles=['Original Ch2', 'Intensity/Noise Ch2'])\n",
    "    show_mag_phase_arrays(original_label_array[0,:,:,:],label_array[0,:,:,:], subtitles=['Original Label', 'Intensity/Noise Label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data augmentation\n",
    "# transform_array.append(RandZoomd(\n",
    "#     keys=['image', 'label'],\n",
    "#     prob=0.1,\n",
    "#     min_zoom=1.0,\n",
    "#     max_zoom=1.3,\n",
    "#     mode=['area', 'nearest'],\n",
    "# ))\n",
    "# transform_array.append(RandFlipd(\n",
    "#     keys=['image', 'label'],\n",
    "#     prob=0.5,\n",
    "#     spatial_axis=2,\n",
    "# ))\n",
    "# # Balance background/foreground\n",
    "# transform_array.append(RandCropByPosNegLabeld(\n",
    "#     keys=[\"image\", \"label\"],\n",
    "#     label_key=\"label\",\n",
    "#     spatial_size=param.window_size,\n",
    "#     pos=5, \n",
    "#     neg=1,\n",
    "#     num_samples=5,\n",
    "#     image_key=\"image\",\n",
    "#     image_threshold=0, \n",
    "# ))\n",
    "\n",
    "# transfTest = Compose(transform_array)\n",
    "# output = transfTest(train_files)\n",
    "# N = len(output[0])\n",
    "# for i in range(N):\n",
    "#     output_dict = output[0][i]\n",
    "#     image = output_dict['image']\n",
    "#     label = output_dict['label']\n",
    "#     image_array = np.array(image)\n",
    "#     label_array = np.array(label)\n",
    "#     print('Image shape: '+ str(image_array.shape))\n",
    "#     print('Label shape: '+ str(label_array.shape))\n",
    "#     show_array(image_array[0,:,:,:], title='Ch1 '+ str(i+1))\n",
    "#     if image_array.shape[0]==2:\n",
    "#         show_array(image_array[1,:,:,:], title='Ch2 '+ str(i+1))\n",
    "#     show_array(label_array[0,:,:,:], title='Label '+ str(i+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run code to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import UNet\n",
    "\n",
    "# # Define the UNet architecture\n",
    "# model_unet = UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=2,\n",
    "#     channels=[16, 32, 64, 128],\n",
    "#     strides=[(1, 2, 2), (1, 2, 2), (1, 1, 1)],\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "\n",
    "# # Create an example input tensor\n",
    "# input_tensor = torch.randn(1, 1, 3, 192, 192)\n",
    "\n",
    "# # Pass the input tensor through the UNet model\n",
    "# output_tensor = model_unet(input_tensor)\n",
    "\n",
    "# # Print the size of the output tensor\n",
    "# print(output_tensor.size())  # Output: torch.Size([1, 2, 3, 192, 192])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
